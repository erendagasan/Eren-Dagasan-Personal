{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erendagasan/Eren-Dagasan-Personal/blob/main/ARIMA-14.09.2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pmdarima"
      ],
      "metadata": {
        "id": "7y_Qvqk2vlh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from pmdarima.arima import auto_arima\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import math\n",
        "import yfinance as yf\n",
        "pd.set_option('display.max_rows', 200)\n",
        "\n",
        "stock = \"RAYSG.IS\"\n",
        "\n",
        "dateparse = lambda dates: pd.datetime.strptime(dates, '%Y-%m-%d')\n",
        "stock_data = yf.download(stock, start=\"2006-01-01\", end=\"2023-09-14\")\n",
        "\n",
        "df_close = stock_data['Close']\n",
        "df_log = np.log(df_close)\n",
        "train_data, test_data = df_log[3:int(len(df_log)*0.9)], df_log[int(len(df_log)*0.9):]\n",
        "\n",
        "# model_autoARIMA = auto_arima(train_data, start_p=0, start_q=0,\n",
        "#                       test='adf',\n",
        "#                       max_p=3, max_q=3,\n",
        "#                       m=1,\n",
        "#                       d=None,\n",
        "#                       seasonal=False,\n",
        "#                       start_P=0,\n",
        "#                       D=0,\n",
        "#                       trace=True,\n",
        "#                       error_action='ignore',\n",
        "#                       suppress_warnings=True,\n",
        "#                       stepwise=True)\n",
        "# best_order = model_autoARIMA.order\n",
        "order_df = pd.read_excel(\"XUTUM_ORDERS.xls\")\n",
        "best_order = order_df[order_df[\"STOCK\"] == stock][\"BEST ORDER\"]\n",
        "\n",
        "print(\"Best ARIMA Order:\", best_order)"
      ],
      "metadata": {
        "id": "yQHoHzSHntPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "start=\"2023-09-19\"\n",
        "end=\"2023-10-03\"\n",
        "\n",
        "stock_data = yf.download(stock, start=start, end=end, progress=False)\n",
        "new_date_index = stock_data.index + pd.Timedelta(days=(pd.Timestamp(end)-pd.Timestamp(start)+pd.Timedelta(1)).days)\n",
        "\n",
        "input_date_str = stock_data.index[-1].strftime(\"%Y-%m-%d\")\n",
        "input_date = datetime.strptime(input_date_str, \"%Y-%m-%d\")\n",
        "future_date = input_date + timedelta(days=len(stock_data) - 1)\n",
        "\n",
        "new_date_index = []\n",
        "current_date = input_date\n",
        "\n",
        "while len(new_date_index) < len(stock_data):\n",
        "    if current_date.weekday() < 5:\n",
        "        new_date_index.append(current_date)\n",
        "    current_date += timedelta(days=1)\n",
        "\n",
        "while len(new_date_index) > len(stock_data):\n",
        "    new_date_index.pop()\n",
        "\n",
        "model = ARIMA(np.log(stock_data[\"Close\"]), order=ast.literal_eval(best_order.values[0]))\n",
        "fitted = model.fit()\n",
        "\n",
        "len(stock_data)"
      ],
      "metadata": {
        "id": "DsNaI26cwFv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "forecast_results = fitted.get_forecast(steps=len(stock_data), alpha=0.05)\n",
        "\n",
        "fc = forecast_results.predicted_mean\n",
        "conf = forecast_results.conf_int()\n",
        "\n",
        "fc_series = pd.Series(fc, index=stock_data.index)\n",
        "lower_series = pd.DataFrame([new_date_index,conf.iloc[:, 0]]).T\n",
        "\n",
        "plt.figure(figsize=(16,6), dpi=100)\n",
        "plt.plot(np.exp(test_data), color='black', label='Test data')\n",
        "\n",
        "today = datetime.now()\n",
        "tomorrow = today + timedelta(days=1)\n",
        "tomorrow = tomorrow.strftime('%Y-%m-%d')\n",
        "\n",
        "end = datetime.strptime(end, \"%Y-%m-%d\")\n",
        "end = end - timedelta(days=1)\n",
        "end = end.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# stock_data = yf.download(stock, start=end, end=tomorrow, progress=False)\n",
        "plt.plot(stock_data.index, stock_data[\"Close\"], color='red', label='Prediction used stock data')\n",
        "\n",
        "stock_data = yf.download(stock, start=end, end=tomorrow, progress=False)\n",
        "plt.plot(stock_data.index, stock_data[\"Close\"], color='orange', label='Live stock data')\n",
        "\n",
        "plt.plot(new_date_index, np.exp(fc), color='blue', label='Predicted stock price')  # Convert back to original scale\n",
        "plt.fill_between(new_date_index, np.exp(conf.iloc[:, 0]), np.exp(conf.iloc[:, 1]),\n",
        "                 color='k', alpha=.10)\n",
        "\n",
        "plt.axhline(np.exp(conf.iloc[:, 1].max()), color=\"green\")\n",
        "plt.axhline(np.exp(conf.iloc[:, 0].min()), color=\"red\")\n",
        "\n",
        "print(\"FİYAT: \", round(stock_data[\"Close\"].iloc[-1], 2), \"TL\\n\")\n",
        "print(\"ÜST PROJEKSİYON: \", round(np.exp(conf.iloc[:, 1].max()), 2), \"TL\")\n",
        "print(\"ALT PROJEKSİYON: \", round(np.exp(conf.iloc[:, 0].min()), 2), \"TL\\n\")\n",
        "\n",
        "print(\"HEDEF FİYAT: \", round(np.exp(fc.iloc[-1]),2), \"TL\\n\")\n",
        "plt.axhline(round(np.exp(fc.iloc[-1]),2), color=\"orange\")\n",
        "\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Price')\n",
        "\n",
        "plt.legend(loc='lower left', fontsize=8)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4mfH8NaHwOHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ARIMA(train_data, order=ast.literal_eval(best_order.values[0]))\n",
        "fitted = model.fit()\n",
        "\n",
        "forecast_results = fitted.get_forecast(steps=len(test_data), alpha=0.05)\n",
        "\n",
        "fc = forecast_results.predicted_mean\n",
        "conf = forecast_results.conf_int()\n",
        "\n",
        "fc_series = pd.Series(fc, index=test_data.index)\n",
        "lower_series = pd.Series(conf.iloc[:, 0], index=test_data.index)\n",
        "upper_series = pd.Series(conf.iloc[:, 1], index=test_data.index)\n",
        "\n",
        "plt.figure(figsize=(16,6), dpi=100)\n",
        "plt.plot(np.exp(train_data[1000:]), label='Training data', color=\"black\")\n",
        "plt.plot(np.exp(test_data), color='blue', label='Test data')\n",
        "\n",
        "plt.plot(test_data.index, np.exp(fc), color='orange', label='Predicted Stock Price')  # Convert back to original scale\n",
        "plt.fill_between(test_data.index, np.exp(conf.iloc[:, 0]), np.exp(conf.iloc[:, 1]),\n",
        "                 color='k', alpha=.10)\n",
        "\n",
        "\n",
        "plt.axhline(np.exp(conf.iloc[:, 1].max()), color=\"green\")\n",
        "plt.axhline(np.exp(conf.iloc[:, 0].min()), color=\"red\")\n",
        "\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Price')\n",
        "\n",
        "plt.legend(loc='lower left', fontsize=8)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YhZP21g9luhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# report performance\n",
        "mse = mean_squared_error(test_data, fc)\n",
        "print('MSE: '+str(mse))\n",
        "mae = mean_absolute_error(test_data, fc)\n",
        "print('MAE: '+str(mae))\n",
        "rmse = math.sqrt(mean_squared_error(test_data, fc))\n",
        "print('RMSE: '+str(rmse))\n",
        "mape = np.mean(np.abs(fc.to_numpy() - test_data)/np.abs(test_data))\n",
        "print('MAPE: '+str(mape))"
      ],
      "metadata": {
        "id": "M8QtrLQzxTyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from pmdarima.arima import auto_arima\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import math\n",
        "import yfinance as yf\n",
        "\n",
        "market = []\n",
        "\n",
        "url = f\"https://tr.tradingview.com/symbols/NASDAQ-NDX/components/\"\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  elements = soup.find_all(class_=\"apply-common-tooltip tickerNameBox-GrtoTeat tickerName-GrtoTeat\")\n",
        "\n",
        "  for element in elements:\n",
        "    text = element.get_text()\n",
        "    market.append(text)\n",
        "\n",
        "# nasdaq100 = ['MARA', 'AAPL', 'MSFT', 'GOOGL', 'GOOG', 'AMZN',\n",
        "#              'NVDA', 'TSLA', 'META', 'AVGO', 'ASML',\n",
        "#              'PEP', 'COST', 'ADBE', 'AZN', 'CSCO',\n",
        "#              'NFLX', 'AMD', 'CMCSA', 'TMUS', 'TXN',\n",
        "#              'QCOM', 'HON', 'INTU', 'INTC', 'SNY',\n",
        "#              'VZ', 'AMGN', 'SBUX', 'ISRG', 'AMAT',\n",
        "#              'BKNG', 'ADI', 'MDLZ', 'PDD', 'GILD',\n",
        "#              'ADP', 'VRTX', 'ABNB', 'LRCX', 'PYPL',\n",
        "#              'REGN', 'EQIX', 'MU', 'CSX', 'SNPS',\n",
        "#              'CME', 'CDNS', 'KLAC', 'NTES']\n",
        "\n",
        "# sheet_id = \"1RSqOXkFTAO7g4H9LEY3d3IX6H6bJaYk1\"\n",
        "# sheet_name = \"Sheet_1\"\n",
        "# url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "# result_df = pd.read_csv(url)\n",
        "\n",
        "bist_best_orders = pd.DataFrame()\n",
        "\n",
        "for stock in market:\n",
        "  try:\n",
        "    print(stock)\n",
        "    dateparse = lambda dates: pd.datetime.strptime(dates, '%Y-%m-%d')\n",
        "    stock_data = yf.download(stock, start=\"2006-01-01\", end=\"2023-09-14\", progress=False)\n",
        "\n",
        "    df_close = stock_data['Close']\n",
        "    df_log = np.log(df_close)\n",
        "    train_data, test_data = df_log[3:int(len(df_log)*0.9)], df_log[int(len(df_log)*0.9):]\n",
        "\n",
        "    model_autoARIMA = auto_arima(train_data, start_p=0, start_q=0,\n",
        "                          test='adf',\n",
        "                          max_p=3, max_q=3,\n",
        "                          m=1,\n",
        "                          d=None,\n",
        "                          seasonal=False,\n",
        "                          start_P=0,\n",
        "                          D=0,\n",
        "                          trace=False,\n",
        "                          error_action='ignore',\n",
        "                          suppress_warnings=True,\n",
        "                          stepwise=True)\n",
        "\n",
        "    best_order = model_autoARIMA.order\n",
        "    bist_best_orders = pd.concat([bist_best_orders, pd.DataFrame([[stock, best_order]], columns=[\"STOCK\", \"BEST ORDER\"])])\n",
        "\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "bist_best_orders.to_excel(\"NASDAQ_ORDERS.xls\")"
      ],
      "metadata": {
        "id": "7xZsSAsxQe_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from pmdarima.arima import auto_arima\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import math\n",
        "import yfinance as yf\n",
        "import ast\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "order_df = pd.read_excel(\"XUTUM_ORDERS.xls\")\n",
        "result_df = pd.DataFrame()\n",
        "\n",
        "for stock in order_df[\"STOCK\"].unique():\n",
        "  try:\n",
        "    best_order = order_df[order_df[\"STOCK\"] == stock][\"BEST ORDER\"]\n",
        "    start=\"2023-09-19\"\n",
        "    end=\"2023-10-03\"\n",
        "\n",
        "    stock_data = yf.download(stock, start=start, end=end, progress=False)\n",
        "\n",
        "    model = ARIMA(np.log(stock_data[\"Close\"]), order=ast.literal_eval(best_order.values[0]))\n",
        "    fitted = model.fit()\n",
        "\n",
        "    forecast_results = fitted.get_forecast(steps=len(stock_data), alpha=0.05)\n",
        "\n",
        "    fc = forecast_results.predicted_mean\n",
        "    conf = forecast_results.conf_int()\n",
        "\n",
        "    fc_series = pd.Series(fc, index=stock_data.index)\n",
        "    lower_series = pd.DataFrame([new_date_index, conf.iloc[:, 0]]).T\n",
        "\n",
        "    last_predict = np.exp(fc.iloc[-1])\n",
        "    first_predict = np.exp((fc.iloc[0]))\n",
        "\n",
        "    new_end_date = pd.Timestamp(end)\n",
        "    weekdays_added = 0\n",
        "    while weekdays_added < 10:\n",
        "        new_end_date += pd.Timedelta(days=1)\n",
        "        if new_end_date.weekday() < 5:\n",
        "            weekdays_added += 1\n",
        "\n",
        "    end_date = datetime.strptime(end, \"%Y-%m-%d\")\n",
        "    while end_date.weekday() >= 5:\n",
        "        end_date -= timedelta(days=1)\n",
        "\n",
        "    stock_data = yf.download(stock, start=end_date, end=new_end_date.strftime(\"%Y-%m-%d\"), progress=False)\n",
        "    period_change = round(((stock_data[\"Close\"].iloc[-1] - stock_data[\"Close\"].iloc[0]) / stock_data[\"Close\"].iloc[0]) * 100, 2)\n",
        "\n",
        "    if (last_predict > ((first_predict) + ((first_predict)*0.5/100))):\n",
        "      result_df = pd.concat([result_df, pd.DataFrame([[stock, \"UP\", round(((last_predict - first_predict) / first_predict) * 100, 2), period_change]])])\n",
        "    if ((last_predict + (last_predict*0.5/100)) < (first_predict)):\n",
        "      result_df = pd.concat([result_df, pd.DataFrame([[stock, \"DOWN\", round(((last_predict - first_predict) / first_predict) * 100, 2), period_change]])])\n",
        "  except:\n",
        "    pass\n",
        "result_df.reset_index(drop=True, inplace=True)\n",
        "result_df = result_df.sort_values(by=2, ascending=False)\n",
        "result_df"
      ],
      "metadata": {
        "id": "A2K-SZKAsksJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05bde03d-6eb0-4ad0-e42d-2ba41aef37ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['AFYON.IS']: Exception('%ticker%: No price data found, symbol may be delisted (1d 2023-10-03 00:00:00 -> 2023-10-17)')\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['AGESA.IS']: Exception('%ticker%: No price data found, symbol may be delisted (1d 2023-10-03 00:00:00 -> 2023-10-17)')\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['AKMGY.IS']: Exception('%ticker%: No price data found, symbol may be delisted (1d 2023-10-03 00:00:00 -> 2023-10-17)')\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['ANSGR.IS']: Exception('%ticker%: No price data found, symbol may be delisted (1d 2023-10-03 00:00:00 -> 2023-10-17)')\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['GARFA.IS']: Exception('%ticker%: No price data found, symbol may be delisted (1d 2023-10-03 00:00:00 -> 2023-10-17)')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from pmdarima.arima import auto_arima\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import math\n",
        "import yfinance as yf\n",
        "import ast\n",
        "from datetime import datetime, timedelta, date\n",
        "\n",
        "def generate_weekday_date_list(start_date, end_date):\n",
        "    current_date = start_date\n",
        "    date_list = []\n",
        "\n",
        "    while current_date <= end_date:\n",
        "        if current_date.weekday() < 5:\n",
        "            date_list.append(current_date.strftime(\"%Y-%m-%d\"))\n",
        "\n",
        "        current_date += timedelta(days=1)\n",
        "\n",
        "    return date_list\n",
        "\n",
        "start_date = date(2020, 1, 1)\n",
        "end_date = date(2023, 12, 31)\n",
        "\n",
        "weekday_date_list = generate_weekday_date_list(start_date, end_date)\n",
        "\n",
        "batch_size = 10\n",
        "date_batches = [weekday_date_list[i:i + batch_size] for i in range(0, len(weekday_date_list), batch_size)]\n",
        "\n",
        "# for index, batch in enumerate(date_batches, start=1):\n",
        "#     print(f\"Batch {index}: {batch}\")\n",
        "\n",
        "# result_df = pd.DataFrame()\n",
        "\n",
        "stock = \"AMZN\"\n",
        "order_df = pd.read_excel(\"NASDAQ_ORDERS.xls\")\n",
        "\n",
        "for index, date in enumerate(date_batches):\n",
        "  best_order = order_df[order_df[\"STOCK\"] == stock][\"BEST ORDER\"]\n",
        "\n",
        "  start=date_batches[index][0]\n",
        "  end=date_batches[index][-1]\n",
        "\n",
        "  stock_data = yf.download(stock, start=start, end=end, progress=False)\n",
        "\n",
        "  new_date_index = stock_data.index + pd.Timedelta(days=(pd.Timestamp(end)-pd.Timestamp(start)+pd.Timedelta(1)).days)\n",
        "\n",
        "  input_date_str = stock_data.index[-1].strftime(\"%Y-%m-%d\")\n",
        "  input_date = datetime.strptime(input_date_str, \"%Y-%m-%d\")\n",
        "  future_date = input_date + timedelta(days=len(stock_data) - 1)\n",
        "\n",
        "  new_date_index = []\n",
        "  current_date = input_date\n",
        "\n",
        "  while len(new_date_index) < len(stock_data):\n",
        "      if current_date.weekday() < 5:\n",
        "          new_date_index.append(current_date)\n",
        "      current_date += timedelta(days=1)\n",
        "\n",
        "  while len(new_date_index) > len(stock_data):\n",
        "      new_date_index.pop()\n",
        "\n",
        "  model = ARIMA(np.log(stock_data[\"Close\"]), order=ast.literal_eval(best_order.values[0]))\n",
        "  fitted = model.fit()\n",
        "\n",
        "  forecast_results = fitted.get_forecast(steps=len(stock_data), alpha=0.05)\n",
        "\n",
        "  fc = forecast_results.predicted_mean\n",
        "  conf = forecast_results.conf_int()\n",
        "\n",
        "  fc_series = pd.Series(fc, index=stock_data.index)\n",
        "  lower_series = pd.DataFrame([new_date_index, conf.iloc[:, 0]]).T\n",
        "\n",
        "  last_predict = np.exp(fc.iloc[-1])\n",
        "  first_predict = np.exp((fc.iloc[0]))\n",
        "\n",
        "  new_end_date = pd.Timestamp(end)\n",
        "  weekdays_added = 0\n",
        "  while weekdays_added < 10:\n",
        "      new_end_date += pd.Timedelta(days=1)\n",
        "      if new_end_date.weekday() < 5:\n",
        "          weekdays_added += 1\n",
        "\n",
        "  end_date = datetime.strptime(end, \"%Y-%m-%d\")\n",
        "  while end_date.weekday() >= 5:\n",
        "      end_date -= timedelta(days=1)\n",
        "\n",
        "  stock_data = yf.download(stock, start=end_date, end=new_end_date.strftime(\"%Y-%m-%d\"), progress=False)\n",
        "\n",
        "  if (last_predict > ((first_predict) + ((first_predict)*0.5/100))):\n",
        "    # result_df = pd.concat([result_df, pd.DataFrame([[stock, \"UP\", round(((last_predict - first_predict) / first_predict) * 100, 2), period_change]])])\n",
        "    period_change = round(((stock_data[\"Close\"].max() - stock_data[\"Close\"].min()) / stock_data[\"Close\"].min()) * 100, 2)\n",
        "    print(start,end,new_date_index[0].strftime(\"%Y-%m-%d\"), new_date_index[-1].strftime(\"%Y-%m-%d\"), round(((last_predict - first_predict) / first_predict) * 100, 2), \"UP\", period_change)\n",
        "  if ((last_predict + (last_predict*0.5/100)) < (first_predict)):\n",
        "    # result_df = pd.concat([result_df, pd.DataFrame([[stock, \"DOWN\", round(((last_predict - first_predict) / first_predict) * 100, 2), period_change]])])\n",
        "    period_change = round(((stock_data[\"Close\"].min() - stock_data[\"Close\"].max()) / stock_data[\"Close\"].max()) * 100, 2)\n",
        "    print(start,end,new_date_index[0].strftime(\"%Y-%m-%d\"), new_date_index[-1].strftime(\"%Y-%m-%d\"), round(((last_predict - first_predict) / first_predict) * 100, 2), \"DOWN\", period_change)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zG_NzijtFGyK",
        "outputId": "55f02e28-ce0b-4590-b2e9-654ef00ef43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020-01-15 2020-01-28 2020-01-27 2020-02-05 1.67 UP 15.14\n",
            "2020-01-29 2020-02-11 2020-02-10 2020-02-20 -4.43 DOWN -7.42\n",
            "2020-02-12 2020-02-25 2020-02-24 2020-03-04 5.8 UP 9.94\n",
            "2020-02-26 2020-03-10 2020-03-09 2020-03-19 -4.16 DOWN -11.89\n",
            "2020-03-25 2020-04-07 2020-04-06 2020-04-16 2.26 UP 19.72\n",
            "2020-04-08 2020-04-21 2020-04-20 2020-04-29 -5.41 DOWN -7.6\n",
            "2020-04-22 2020-05-05 2020-05-04 2020-05-14 -2.65 DOWN -4.47\n",
            "2020-05-06 2020-05-19 2020-05-18 2020-05-28 -0.75 DOWN -3.88\n",
            "2020-05-20 2020-06-02 2020-06-01 2020-06-10 -0.76 DOWN -7.06\n",
            "2020-06-17 2020-06-30 2020-06-29 2020-07-09 0.65 UP 15.99\n",
            "2020-07-01 2020-07-14 2020-07-13 2020-07-22 -0.95 DOWN -7.35\n",
            "2020-09-09 2020-09-22 2020-09-21 2020-10-01 4.02 UP 7.38\n",
            "2020-09-23 2020-10-06 2020-10-05 2020-10-15 -1.34 DOWN -9.98\n",
            "2020-10-07 2020-10-20 2020-10-19 2020-10-29 1.78 UP 9.38\n",
            "2020-10-21 2020-11-03 2020-11-02 2020-11-12 4.43 UP 9.46\n",
            "2020-11-04 2020-11-17 2020-11-16 2020-11-26 1.0 UP 3.13\n",
            "2020-12-30 2021-01-12 2021-01-11 2021-01-20 0.68 UP 6.53\n",
            "2021-01-13 2021-01-26 2021-01-25 2021-02-03 -0.8 DOWN -5.14\n",
            "2021-02-10 2021-02-23 2021-02-22 2021-03-03 0.95 UP 8.22\n",
            "2021-02-24 2021-03-09 2021-03-08 2021-03-18 3.36 UP 3.56\n",
            "2021-03-24 2021-04-06 2021-04-05 2021-04-14 -2.55 DOWN -5.18\n",
            "2021-04-21 2021-05-04 2021-05-03 2021-05-13 0.81 UP 5.07\n",
            "2021-05-05 2021-05-18 2021-05-17 2021-05-27 -0.59 DOWN -1.9\n",
            "2021-06-02 2021-06-15 2021-06-14 2021-06-24 -1.79 DOWN -3.49\n",
            "2021-06-16 2021-06-29 2021-06-28 2021-07-08 -0.73 DOWN -8.0\n",
            "2021-06-30 2021-07-13 2021-07-12 2021-07-21 -1.46 DOWN -4.06\n",
            "2021-07-14 2021-07-27 2021-07-26 2021-08-05 -0.96 DOWN -8.34\n",
            "2021-08-25 2021-09-07 2021-09-03 2021-09-14 -1.64 DOWN -4.82\n",
            "2021-09-08 2021-09-21 2021-09-20 2021-09-30 2.08 UP 7.39\n",
            "2021-09-22 2021-10-05 2021-10-04 2021-10-14 4.45 UP 7.01\n",
            "2021-10-06 2021-10-19 2021-10-18 2021-10-28 -2.42 DOWN -3.73\n",
            "2021-11-17 2021-11-30 2021-11-29 2021-12-08 -1.17 DOWN -3.79\n",
            "2021-12-01 2021-12-14 2021-12-13 2021-12-23 1.03 UP 3.73\n",
            "2021-12-29 2022-01-11 2022-01-10 2022-01-20 1.84 UP 15.93\n",
            "2022-01-12 2022-01-25 2022-01-24 2022-02-02 7.53 UP 13.75\n",
            "2022-01-26 2022-02-08 2022-02-07 2022-02-17 0.96 UP 5.77\n",
            "2022-02-09 2022-02-22 2022-02-18 2022-03-01 -0.62 DOWN -10.62\n",
            "2022-02-23 2022-03-08 2022-03-07 2022-03-17 5.11 UP 18.73\n",
            "2022-03-09 2022-03-22 2022-03-21 2022-03-31 -5.5 DOWN -3.73\n",
            "2022-03-23 2022-04-05 2022-04-04 2022-04-14 -0.86 DOWN -8.09\n",
            "2022-04-20 2022-05-03 2022-05-02 2022-05-12 2.29 UP 19.51\n",
            "2022-05-18 2022-05-31 2022-05-27 2022-06-07 -3.24 DOWN -17.4\n",
            "2022-06-01 2022-06-14 2022-06-13 2022-06-23 7.81 UP 13.83\n",
            "2022-06-29 2022-07-12 2022-07-11 2022-07-20 0.83 UP 14.11\n",
            "2022-07-13 2022-07-26 2022-07-25 2022-08-04 -2.69 DOWN -19.47\n",
            "2022-07-27 2022-08-09 2022-08-08 2022-08-18 -2.89 DOWN -7.98\n",
            "2022-08-10 2022-08-23 2022-08-22 2022-09-01 5.97 UP 8.29\n",
            "2022-08-24 2022-09-06 2022-09-02 2022-09-13 1.89 UP 10.46\n",
            "2022-09-07 2022-09-20 2022-09-19 2022-09-29 1.41 UP 8.13\n",
            "2022-09-21 2022-10-04 2022-10-03 2022-10-13 -0.52 DOWN -11.72\n",
            "2022-10-05 2022-10-18 2022-10-17 2022-10-27 0.76 UP 17.73\n",
            "2022-10-19 2022-11-01 2022-10-31 2022-11-10 8.63 UP 17.01\n",
            "2022-11-16 2022-11-29 2022-11-28 2022-12-07 1.0 UP 9.39\n",
            "2022-11-30 2022-12-13 2022-12-12 2022-12-22 0.63 UP 10.38\n",
            "2022-12-14 2022-12-27 2022-12-23 2023-01-03 3.26 UP 6.77\n",
            "2023-01-11 2023-01-24 2023-01-23 2023-02-01 1.19 UP 17.22\n",
            "2023-01-25 2023-02-07 2023-02-06 2023-02-16 3.1 UP 5.05\n",
            "2023-02-08 2023-02-21 2023-02-17 2023-02-28 -0.82 DOWN -3.85\n",
            "2023-02-22 2023-03-07 2023-03-06 2023-03-16 0.78 UP 10.26\n",
            "2023-03-08 2023-03-21 2023-03-20 2023-03-30 -1.46 DOWN -5.86\n",
            "2023-03-22 2023-04-04 2023-04-03 2023-04-13 -1.25 DOWN -5.89\n",
            "2023-05-03 2023-05-16 2023-05-15 2023-05-25 -3.38 DOWN -5.59\n",
            "2023-05-17 2023-05-30 2023-05-26 2023-06-06 2.62 UP 5.0\n",
            "2023-05-31 2023-06-13 2023-06-12 2023-06-22 1.02 UP 4.26\n",
            "2023-06-28 2023-07-11 2023-07-10 2023-07-19 -0.74 DOWN -4.86\n",
            "2023-07-12 2023-07-25 2023-07-24 2023-08-03 0.69 UP 10.98\n",
            "2023-07-26 2023-08-08 2023-08-07 2023-08-17 -1.44 DOWN -5.23\n",
            "2023-08-23 2023-09-05 2023-09-01 2023-09-12 -1.17 DOWN -6.55\n",
            "2023-09-06 2023-09-19 2023-09-18 2023-09-28 0.75 UP 9.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['AMZN']: Exception(\"%ticker%: Data doesn't exist for startDate = 1696305600, endDate = 1697515200\")\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['AMZN']: Exception(\"%ticker%: Data doesn't exist for startDate = 1696392000, endDate = 1697515200\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-20 2023-10-03 2023-09-29 2023-10-10 -1.84 DOWN nan\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-f1fa42e60c4a>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0mnew_date_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstock_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0minput_date_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstock_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0minput_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_date_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0mfuture_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_date\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5318\u001b[0m             \u001b[0;31m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5319\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index -1 is out of bounds for axis 0 with size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deneme"
      ],
      "metadata": {
        "id": "NxP5zIRJGbkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split, ParameterGrid\n",
        "from ta import momentum, trend\n",
        "import yfinance as yf\n",
        "\n",
        "stock_symbol = 'ULKER.IS'\n",
        "start_date = '2000-01-01'\n",
        "end_date = '2023-12-31'\n",
        "\n",
        "data = yf.download(stock_symbol, start=start_date, end=end_date)\n",
        "\n",
        "# data['RSI'] = momentum.RSIIndicator(data['Close'], window=14).rsi()\n",
        "# data['SMA-9'] = trend.SMAIndicator(data['Close'], window=9).sma_indicator()\n",
        "# data['SMA-14'] = trend.SMAIndicator(data['Close'], window=14).sma_indicator()\n",
        "# data['EMA-9'] = trend.EMAIndicator(data['Close'], window=9).ema_indicator()\n",
        "# data['EMA-14'] = trend.EMAIndicator(data['Close'], window=14).ema_indicator()\n",
        "\n",
        "\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "train_size = int(0.8 * len(data))\n",
        "train_data, test_data = data.iloc[:train_size], data.iloc[train_size:]\n",
        "\n",
        "# p_values = [0, 1, 2]\n",
        "# d_values = [0, 1]\n",
        "# q_values = [0, 1, 2]\n",
        "# P_values = [0, 1, 2]\n",
        "# D_values = [0, 1]\n",
        "# Q_values = [0, 1, 2]\n",
        "# s_values = [12]\n",
        "\n",
        "best_order = (5,1,0)\n",
        "best_seasonal_order = (1,1,1,12)\n",
        "\n",
        "# for param in ParameterGrid({'p': p_values, 'd': d_values, 'q': q_values,\n",
        "#                             'P': P_values, 'D': D_values, 'Q': Q_values, 's': s_values}):\n",
        "#     try:\n",
        "#         order = (param['p'], param['d'], param['q'])\n",
        "#         seasonal_order = (param['P'], param['D'], param['Q'], param['s'])\n",
        "\n",
        "#         model = SARIMAX(train_data['Close'], exog=train_data[['RSI', 'SMA-9', 'SMA-14', 'EMA-9', \"EMA-14\"]], order=order, seasonal_order=seasonal_order)\n",
        "#         model_fit = model.fit(disp=0)\n",
        "\n",
        "#         exog_test = test_data[['RSI', 'SMA-9', 'SMA-14', 'EMA-9', \"EMA-14\"]]\n",
        "#         predictions = model_fit.forecast(steps=len(test_data), exog=exog_test)\n",
        "\n",
        "#         mse = mean_squared_error(test_data['Close'], predictions)\n",
        "#         rmse = np.sqrt(mse)\n",
        "\n",
        "#         if rmse < best_rmse:\n",
        "#             best_rmse = rmse\n",
        "#             best_order = order\n",
        "#             best_seasonal_order = seasonal_order\n",
        "\n",
        "#     except Exception as e:\n",
        "#         continue\n",
        "\n",
        "# Best SARIMA Order: (0, 0, 2)\n",
        "# Best SARIMA Seasonal Order: (2, 1, 1, 12)\n",
        "\n",
        "best_model = SARIMAX(train_data['Close'], exog=train_data[['RSI', 'SMA-9', 'SMA-14', 'EMA-9', \"EMA-14\"]], order=(0,0,2), seasonal_order=(2,1,1,12))\n",
        "best_model_fit = best_model.fit(disp=0)\n",
        "best_predictions = best_model_fit.forecast(steps=len(test_data), exog=test_data[['RSI', 'SMA-9', 'SMA-14', 'EMA-9', \"EMA-14\"]])\n",
        "\n",
        "mse = mean_squared_error(test_data['Close'], best_predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"Best SARIMA Order: {best_order}\")\n",
        "print(f\"Best SARIMA Seasonal Order: {best_seasonal_order}\")\n",
        "print(f\"Best Root Mean Squared Error (RMSE): {rmse}\")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(test_data.index, test_data['Close'], label='Actual', color='blue')\n",
        "plt.plot(test_data.index, best_predictions, label='Predicted', color='red')\n",
        "plt.title(f'Stock Price Prediction for {stock_symbol} with Best SARIMA Model and Exogenous Features')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Closing Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pgIu-ZD1Mf6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "input_date_str = test_data.index[-1] + timedelta(days=1)\n",
        "input_date_str = input_date_str.strftime(\"%Y-%m-%d\")\n",
        "input_date = datetime.strptime(input_date_str, \"%Y-%m-%d\")\n",
        "future_date = input_date + timedelta(days=13)\n",
        "date_list = []\n",
        "current_date = input_date\n",
        "while current_date <= future_date:\n",
        "    date_list.append(current_date)\n",
        "    current_date += timedelta(days=1)\n",
        "\n",
        "forecast_period = 14\n",
        "exog_forecast = data[['RSI', 'SMA-9', 'SMA-14', 'EMA-9', \"EMA-14\"]].tail(forecast_period)\n",
        "forecast = best_model_fit.forecast(steps=forecast_period, exog=exog_forecast)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(test_data.index[500:], test_data['Close'][500:], label='Actual', color='blue')\n",
        "plt.plot(test_data.index[500:], best_predictions[500:], label='Predicted', color='red')\n",
        "plt.plot(date_list, forecast.values, label='Future Prediction', color='orange')\n",
        "plt.title(f'Stock Price Prediction for {stock_symbol} with Best SARIMA Model and Exogenous Features')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Closing Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KJtQNxuECz47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_horizon = 30\n",
        "\n",
        "last_available_date = data.index[-1]\n",
        "next_dates = pd.date_range(start=last_available_date + pd.Timedelta(days=1), periods=forecast_horizon, freq='D')\n",
        "next_features = pd.DataFrame(index=next_dates)\n",
        "next_features['RSI'] = data['RSI'].tail(7).mean()\n",
        "next_features['SMA-9'] = data['SMA-9'].tail(7).mean()\n",
        "next_features['SMA-14'] = data['SMA-14'].tail(7).mean()\n",
        "next_features['EMA-9'] = data['EMA-9'].tail(7).mean()\n",
        "next_features['EMA-14'] = data['EMA-14'].tail(7).mean()\n",
        "\n",
        "forecast = best_model_fit.forecast(steps=forecast_horizon, exog=next_features)\n",
        "\n",
        "print(\"Forecasted Closing Prices for the Next 7 Days:\")\n",
        "print(forecast)\n",
        "print(data[\"Close\"].iloc[-1])\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(data.index[len(data)-200:], data['Close'][len(data)-200:], label='Actual', color='blue')\n",
        "plt.plot(next_dates, forecast, label='Forecasted', color='green')\n",
        "plt.title(f'Stock Price Forecast for {stock_symbol} for the Next 7 Days')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Closing Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6CvwQQX2w6a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the stock symbol and time frame\n",
        "stock_symbol = \"HEKTS.IS\"  # Change this to the desired stock symbol\n",
        "start_date = \"2020-01-01\"\n",
        "end_date = \"2023-12-31\"\n",
        "\n",
        "# Fetch stock price data from Yahoo Finance\n",
        "data = yf.download(stock_symbol, start=start_date, end=end_date)\n",
        "\n",
        "# Select only the 'Close' prices\n",
        "df = data[['Close']]\n",
        "\n",
        "# Define the number of periods ahead for prediction (1 week = 5 trading days)\n",
        "forecast_periods = 31\n",
        "\n",
        "# Perform differencing to make the time series stationary\n",
        "df['Diff'] = df['Close'].diff().dropna()\n",
        "\n",
        "# Fit SARIMAX model\n",
        "order = (0, 0, 2)  # Replace with appropriate order parameters\n",
        "seasonal_order = (1, 1, 1, 12)  # Replace with appropriate seasonal order parameters\n",
        "exog_variables = None  # Add exogenous variables if needed\n",
        "\n",
        "model = SARIMAX(df['Diff'], order=order, seasonal_order=seasonal_order, exog=exog_variables)\n",
        "results = model.fit()\n",
        "\n",
        "# Forecast next week's stock prices\n",
        "forecast = results.forecast(steps=forecast_periods)\n",
        "\n",
        "# Create a date range for the forecast period\n",
        "last_date = df.index[-1]\n",
        "forecast_dates = pd.date_range(start=last_date, periods=forecast_periods + 2, closed='right')\n",
        "\n",
        "# Invert differencing to get the actual stock price forecast\n",
        "forecast_values = np.cumsum(np.concatenate(([df['Close'].iloc[-1]], forecast)))\n",
        "\n",
        "# Create a DataFrame for the forecast\n",
        "forecast_df = pd.DataFrame({'Date': forecast_dates, 'Forecast': forecast_values})\n",
        "\n",
        "# Plot the historical data and the forecast\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df.index, df['Close'], label='Historical Data', color='blue')\n",
        "plt.plot(forecast_df['Date'], forecast_df['Forecast'], label='Forecast', color='red', linestyle='--')\n",
        "plt.title(f'Stock Price Forecast for {stock_symbol}')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Display the forecast\n",
        "print(forecast_df)"
      ],
      "metadata": {
        "id": "SHjchj4FyqFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f0gVugGZAfPn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
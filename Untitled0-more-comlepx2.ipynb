{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erendagasan/Eren-Dagasan-Personal/blob/main/Untitled0-more-comlepx2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Libraries and Indicator Function\n",
        "\n",
        "!pip install -q bta-lib\n",
        "!pip install -q ta\n",
        "\n",
        "import btalib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ta.trend import PSARIndicator\n",
        "from ta.momentum import WilliamsRIndicator\n",
        "from ta.trend import AroonIndicator\n",
        "from ta.volume import VolumePriceTrendIndicator\n",
        "from ta.trend import CCIIndicator\n",
        "from ta.momentum import ROCIndicator\n",
        "from ta.trend import ADXIndicator\n",
        "import yfinance as yf\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "def create_indicators(data):\n",
        "  data[\"RSI\"] = btalib.rsi(data[\"Close\"], period=14).df\n",
        "  data[\"SMA5\"] = btalib.sma(data['Close'], period=5).df\n",
        "  data[\"SMA9\"] = btalib.sma(data['Close'], period=9).df\n",
        "  data[\"SMA10\"] = btalib.sma(data['Close'], period=10).df\n",
        "  data[\"SMA14\"] = btalib.sma(data['Close'], period=14).df\n",
        "  data[\"SMA20\"] = btalib.sma(data['Close'], period=20).df\n",
        "  data[\"SMA21\"] = btalib.sma(data['Close'], period=21).df\n",
        "  data[\"SMA50\"] = btalib.sma(data['Close'], period=50).df\n",
        "  data[\"SMA200\"] = btalib.sma(data['Close'], period=200).df\n",
        "  data[\"EMA5\"] = btalib.ema(data['Close'], period=5).df\n",
        "  data[\"EMA14\"] = btalib.ema(data['Close'], period=14).df\n",
        "  data[\"EMA21\"] = btalib.ema(data['Close'], period=21).df\n",
        "  data[\"EMA50\"] = btalib.ema(data['Close'], period=50).df\n",
        "  data[\"STOCH-K\"] = btalib.stoch(data['High'], data['Low'], data['Close']).df[\"k\"]\n",
        "  data[\"STOCH-D\"] = btalib.stoch(data['High'], data['Low'], data['Close']).df[\"d\"]\n",
        "  data[\"MACD\"] = btalib.macd(data['Close']).df[\"macd\"]\n",
        "  data[\"SIGNAL\"] = btalib.macd(data['Close']).df[\"signal\"]\n",
        "  data[\"HISTOGRAM\"] = btalib.macd(data['Close']).df[\"histogram\"]\n",
        "  data[\"BB-UPPER\"] = btalib.bbands(data['Close']).df['top']\n",
        "  data[\"BB-MID\"] = btalib.bbands(data['Close']).df['mid']\n",
        "  data[\"BB-LOWER\"] = btalib.bbands(data['Close']).df['bot']\n",
        "  data[\"STDEV\"] = data[\"Close\"].rolling(window=10).std()\n",
        "  data[\"PSAR\"] = PSARIndicator(data[\"High\"], data[\"Low\"], data[\"Close\"]).psar()\n",
        "  data[\"WILLIAMS\"] = WilliamsRIndicator(data[\"High\"], data[\"Low\"], data[\"Close\"]).williams_r()\n",
        "  data[\"AROON\"] = AroonIndicator(close=data[\"Close\"], window=25).aroon_indicator()\n",
        "  data[\"OBV\"] = VolumePriceTrendIndicator(close=data['Close'], volume=data['Volume']).volume_price_trend()\n",
        "  data['CCI'] = CCIIndicator(close=data['Close'], low=data[\"Low\"], high=data[\"High\"], window=14).cci()\n",
        "  data['ROC'] = ROCIndicator(close=data['Close'], window=5).roc()\n",
        "  data['BULL'] = data['High'] - (data['High'].rolling(13).max() + data['Low'].rolling(13).min()) / 2\n",
        "  data['BEAR'] = data['Low'] - (data['High'].rolling(13).max() + data['Low'].rolling(13).min()) / 2\n",
        "  adx_indicator = ADXIndicator(high=data['High'], low=data['Low'], close=data['Close'], window=14)\n",
        "  data['ADX'] = adx_indicator.adx()\n",
        "  data['+DI'] = adx_indicator.adx_pos()\n",
        "  data['-DI'] = adx_indicator.adx_neg()\n",
        "\n",
        "  data = data.dropna()\n",
        "  data = data.reset_index()\n",
        "  return data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Lfv1WZ9SIIPB",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67dc0ead-9cd8-4b74-c22a-0cd7839ac108"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/92.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the Model\n",
        "\n",
        "import gdown\n",
        "\n",
        "gdown.download(\"https://drive.google.com/u/1/uc?id=1qWKIj9rzRzyW3GQFw9xISs4eXmjyIDng&export=download\", \"/content/\", quiet=False)\n",
        "gdown.download(\"https://drive.google.com/u/0/uc?id=117pezAA6jRLCwIsdpEhZgEa9tEanlC0O&export=download\", \"/content/\", quiet=False)\n",
        "\n",
        "data = pd.read_csv(\"data.csv\")\n",
        "model = tf.keras.models.load_model(\"best_model.h5\")"
      ],
      "metadata": {
        "id": "j0_ac_MyLUax",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Stock List\n",
        "sheet_id = \"1RSqOXkFTAO7g4H9LEY3d3IX6H6bJaYk1\"\n",
        "sheet_name = \"Sheet_1\"\n",
        "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "result_df = pd.read_csv(url)\n",
        "\n",
        "sheet_id = \"1AA9MfqOtAAgO97__aomD79DciyT-PkRQ\"\n",
        "sheet_name = \"Sheet_1\"\n",
        "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "result_df = pd.read_csv(url)\n",
        "\n",
        "nasdaq100 = ['AAPL', 'MSFT', 'GOOGL', 'GOOG', 'AMZN',\n",
        "             'NVDA', 'TSLA', 'META', 'AVGO', 'ASML',\n",
        "             'PEP', 'COST', 'ADBE', 'AZN', 'CSCO',\n",
        "             'NFLX', 'AMD', 'CMCSA', 'TMUS', 'TXN',\n",
        "             'QCOM', 'HON', 'INTU', 'INTC', 'SNY',\n",
        "             'VZ', 'AMGN', 'SBUX', 'ISRG', 'AMAT',\n",
        "             'BKNG', 'ADI', 'MDLZ', 'PDD', 'GILD',\n",
        "             'ADP', 'VRTX', 'ABNB', 'LRCX', 'PYPL',\n",
        "             'REGN', 'EQIX', 'MU', 'CSX', 'SNPS',\n",
        "             'CME', 'CDNS', 'KLAC', 'NTES']"
      ],
      "metadata": {
        "id": "3g0KHl4YMTKd",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Preprocessing\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "input_columns = df.columns[:33]\n",
        "output_column = \"signal\"\n",
        "\n",
        "df[output_column] = df[output_column].astype(int)\n",
        "\n",
        "X = df[input_columns].values\n",
        "y = df[output_column].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight(\"balanced\", classes=[0, 1], y=y_train)\n",
        "class_weight = {cls: weight for cls, weight in zip([0, 1], class_weights)}\n",
        "class_weight"
      ],
      "metadata": {
        "cellView": "form",
        "id": "K-Gz1pgOMh8j",
        "outputId": "f11f498e-4fd2-410b-8a16-ecaa93ead3c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.5702985455473335, 1: 4.056261343012705}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LSTM Model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train_resampled.shape[1], 1)),\n",
        "\n",
        "    tf.keras.layers.LSTM(512, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.LSTM(512, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.LSTM(256),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
        "\n",
        "model.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=256, validation_split=0.2, callbacks=[early_stopping, model_checkpoint])"
      ],
      "metadata": {
        "id": "IfSHE91eZonR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame()\n",
        "\n",
        "for stock in [\"AMZN\"]:\n",
        "  stock_df = yf.download(stock, start=\"2000-01-01\", end=\"2023-01-01\", progress=False)\n",
        "  stock_df = create_indicators(stock_df)\n",
        "  stock_df[\"signal\"] = 0\n",
        "\n",
        "  for index, row in stock_df.iterrows():\n",
        "    if index > 0 and index < stock_df.shape[0]-1 and stock_df[\"Close\"].iloc[index+1] > ((2.5*stock_df[\"Close\"].iloc[index]/100) + stock_df[\"Close\"].iloc[index]):\n",
        "      stock_df[\"signal\"].iloc[index] = 1\n",
        "\n",
        "  stock_df = stock_df.drop([\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Adj Close\"], axis=1)\n",
        "\n",
        "  data = pd.concat([data, stock_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "pG05JgnZQonH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "\n",
        "X_train_resampled = np.expand_dims(X_train_resampled, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "# # Add Convolutional layers\n",
        "# model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_resampled.shape[1], X_train_resampled.shape[2])))\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(GlobalMaxPooling1D())\n",
        "\n",
        "# # Add Dense layers\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/nasdaq_2_5.h5', save_best_only=True)\n",
        "\n",
        "model.fit(X_train_resampled, y_train_resampled, epochs=300, batch_size=8, validation_split=0.2,\n",
        "          callbacks=[model_checkpoint])\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "J1wt4y6SAmBR",
        "outputId": "60d59bbc-a2ae-44eb-d40f-ebce60cf218c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "784/784 [==============================] - 8s 7ms/step - loss: 0.5272 - accuracy: 0.8419 - val_loss: 0.5719 - val_accuracy: 0.8737\n",
            "Epoch 2/300\n",
            "784/784 [==============================] - 4s 6ms/step - loss: 0.3387 - accuracy: 0.8515 - val_loss: 0.3168 - val_accuracy: 0.9337\n",
            "Epoch 3/300\n",
            "784/784 [==============================] - 5s 6ms/step - loss: 0.3340 - accuracy: 0.8520 - val_loss: 0.3717 - val_accuracy: 0.9094\n",
            "Epoch 4/300\n",
            "784/784 [==============================] - 6s 7ms/step - loss: 0.3100 - accuracy: 0.8638 - val_loss: 0.3478 - val_accuracy: 0.9247\n",
            "Epoch 5/300\n",
            "784/784 [==============================] - 5s 6ms/step - loss: 0.2814 - accuracy: 0.8724 - val_loss: 0.1831 - val_accuracy: 0.9700\n",
            "Epoch 6/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.2729 - accuracy: 0.8810 - val_loss: 0.4331 - val_accuracy: 0.8565\n",
            "Epoch 7/300\n",
            "784/784 [==============================] - 5s 7ms/step - loss: 0.2623 - accuracy: 0.8861 - val_loss: 0.2745 - val_accuracy: 0.9426\n",
            "Epoch 8/300\n",
            "784/784 [==============================] - 4s 6ms/step - loss: 0.2384 - accuracy: 0.8925 - val_loss: 0.2180 - val_accuracy: 0.9496\n",
            "Epoch 9/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.2365 - accuracy: 0.8968 - val_loss: 0.3062 - val_accuracy: 0.9260\n",
            "Epoch 10/300\n",
            "784/784 [==============================] - 5s 7ms/step - loss: 0.2232 - accuracy: 0.8978 - val_loss: 0.2411 - val_accuracy: 0.9298\n",
            "Epoch 11/300\n",
            "784/784 [==============================] - 5s 6ms/step - loss: 0.2410 - accuracy: 0.8947 - val_loss: 0.2900 - val_accuracy: 0.9286\n",
            "Epoch 12/300\n",
            "784/784 [==============================] - 4s 6ms/step - loss: 0.2108 - accuracy: 0.9067 - val_loss: 0.2895 - val_accuracy: 0.9094\n",
            "Epoch 13/300\n",
            "784/784 [==============================] - 6s 8ms/step - loss: 0.2296 - accuracy: 0.8974 - val_loss: 0.2931 - val_accuracy: 0.9228\n",
            "Epoch 14/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.2068 - accuracy: 0.9096 - val_loss: 0.3147 - val_accuracy: 0.9209\n",
            "Epoch 15/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.1984 - accuracy: 0.9110 - val_loss: 0.2317 - val_accuracy: 0.9426\n",
            "Epoch 16/300\n",
            "784/784 [==============================] - 5s 7ms/step - loss: 0.2248 - accuracy: 0.9032 - val_loss: 0.2219 - val_accuracy: 0.9228\n",
            "Epoch 17/300\n",
            "784/784 [==============================] - 4s 6ms/step - loss: 0.1971 - accuracy: 0.9136 - val_loss: 0.1724 - val_accuracy: 0.9668\n",
            "Epoch 18/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.2070 - accuracy: 0.9115 - val_loss: 0.1526 - val_accuracy: 0.9688\n",
            "Epoch 19/300\n",
            "784/784 [==============================] - 5s 7ms/step - loss: 0.2075 - accuracy: 0.9115 - val_loss: 0.2348 - val_accuracy: 0.9324\n",
            "Epoch 20/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.2049 - accuracy: 0.9091 - val_loss: 0.1756 - val_accuracy: 0.9458\n",
            "Epoch 21/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.1863 - accuracy: 0.9164 - val_loss: 0.2522 - val_accuracy: 0.9343\n",
            "Epoch 22/300\n",
            "784/784 [==============================] - 6s 7ms/step - loss: 0.1780 - accuracy: 0.9231 - val_loss: 0.1499 - val_accuracy: 0.9700\n",
            "Epoch 23/300\n",
            "784/784 [==============================] - 5s 6ms/step - loss: 0.1960 - accuracy: 0.9120 - val_loss: 0.1570 - val_accuracy: 0.9809\n",
            "Epoch 24/300\n",
            "784/784 [==============================] - 5s 7ms/step - loss: 0.2104 - accuracy: 0.9102 - val_loss: 0.2268 - val_accuracy: 0.9503\n",
            "Epoch 25/300\n",
            "784/784 [==============================] - 5s 7ms/step - loss: 0.1702 - accuracy: 0.9223 - val_loss: 0.2130 - val_accuracy: 0.9490\n",
            "Epoch 26/300\n",
            "784/784 [==============================] - 5s 6ms/step - loss: 0.1864 - accuracy: 0.9201 - val_loss: 0.1560 - val_accuracy: 0.9764\n",
            "Epoch 27/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.1873 - accuracy: 0.9190 - val_loss: 0.2346 - val_accuracy: 0.9362\n",
            "Epoch 28/300\n",
            "784/784 [==============================] - 6s 7ms/step - loss: 0.2080 - accuracy: 0.9182 - val_loss: 0.1637 - val_accuracy: 0.9630\n",
            "Epoch 29/300\n",
            "784/784 [==============================] - 5s 6ms/step - loss: 0.1669 - accuracy: 0.9241 - val_loss: 0.1314 - val_accuracy: 0.9758\n",
            "Epoch 30/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.1854 - accuracy: 0.9201 - val_loss: 0.2174 - val_accuracy: 0.9496\n",
            "Epoch 31/300\n",
            "784/784 [==============================] - 5s 7ms/step - loss: 0.1685 - accuracy: 0.9266 - val_loss: 0.1448 - val_accuracy: 0.9694\n",
            "Epoch 32/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.1794 - accuracy: 0.9207 - val_loss: 0.2570 - val_accuracy: 0.9082\n",
            "Epoch 33/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.1887 - accuracy: 0.9211 - val_loss: 0.2090 - val_accuracy: 0.9464\n",
            "Epoch 34/300\n",
            "784/784 [==============================] - 5s 6ms/step - loss: 0.1696 - accuracy: 0.9266 - val_loss: 0.1828 - val_accuracy: 0.9643\n",
            "Epoch 35/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.1536 - accuracy: 0.9340 - val_loss: 0.1525 - val_accuracy: 0.9719\n",
            "Epoch 36/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.1816 - accuracy: 0.9228 - val_loss: 0.1693 - val_accuracy: 0.9681\n",
            "Epoch 37/300\n",
            "784/784 [==============================] - 5s 6ms/step - loss: 0.1801 - accuracy: 0.9242 - val_loss: 0.1853 - val_accuracy: 0.9394\n",
            "Epoch 38/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.1684 - accuracy: 0.9238 - val_loss: 0.1496 - val_accuracy: 0.9713\n",
            "Epoch 39/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.1702 - accuracy: 0.9279 - val_loss: 0.2106 - val_accuracy: 0.9432\n",
            "Epoch 40/300\n",
            "784/784 [==============================] - 5s 6ms/step - loss: 0.1630 - accuracy: 0.9293 - val_loss: 0.1430 - val_accuracy: 0.9866\n",
            "Epoch 41/300\n",
            "784/784 [==============================] - 4s 6ms/step - loss: 0.1708 - accuracy: 0.9298 - val_loss: 0.1841 - val_accuracy: 0.9630\n",
            "Epoch 42/300\n",
            "784/784 [==============================] - 4s 6ms/step - loss: 0.1618 - accuracy: 0.9317 - val_loss: 0.1303 - val_accuracy: 0.9726\n",
            "Epoch 43/300\n",
            "784/784 [==============================] - 5s 6ms/step - loss: 0.1550 - accuracy: 0.9325 - val_loss: 0.0960 - val_accuracy: 0.9930\n",
            "Epoch 44/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.1630 - accuracy: 0.9311 - val_loss: 0.1970 - val_accuracy: 0.9515\n",
            "Epoch 45/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.1618 - accuracy: 0.9309 - val_loss: 0.2186 - val_accuracy: 0.9464\n",
            "Epoch 46/300\n",
            "784/784 [==============================] - 5s 6ms/step - loss: 0.1628 - accuracy: 0.9322 - val_loss: 0.1082 - val_accuracy: 0.9821\n",
            "Epoch 47/300\n",
            "784/784 [==============================] - 5s 6ms/step - loss: 0.1501 - accuracy: 0.9348 - val_loss: 0.1330 - val_accuracy: 0.9802\n",
            "Epoch 48/300\n",
            "784/784 [==============================] - 5s 7ms/step - loss: 0.1847 - accuracy: 0.9255 - val_loss: 0.1730 - val_accuracy: 0.9560\n",
            "Epoch 49/300\n",
            "784/784 [==============================] - 5s 7ms/step - loss: 0.1456 - accuracy: 0.9354 - val_loss: 0.3543 - val_accuracy: 0.8941\n",
            "Epoch 50/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.1580 - accuracy: 0.9311 - val_loss: 0.1582 - val_accuracy: 0.9694\n",
            "Epoch 51/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.1823 - accuracy: 0.9250 - val_loss: 0.1092 - val_accuracy: 0.9923\n",
            "Epoch 52/300\n",
            "784/784 [==============================] - 5s 6ms/step - loss: 0.1547 - accuracy: 0.9378 - val_loss: 0.1344 - val_accuracy: 0.9726\n",
            "Epoch 53/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.1618 - accuracy: 0.9325 - val_loss: 0.1392 - val_accuracy: 0.9694\n",
            "Epoch 54/300\n",
            "784/784 [==============================] - 4s 5ms/step - loss: 0.1593 - accuracy: 0.9297 - val_loss: 0.1799 - val_accuracy: 0.9541\n",
            "Epoch 55/300\n",
            "784/784 [==============================] - 5s 6ms/step - loss: 0.1526 - accuracy: 0.9327 - val_loss: 0.1642 - val_accuracy: 0.9541\n",
            "Epoch 56/300\n",
            "784/784 [==============================] - 5s 6ms/step - loss: 0.1522 - accuracy: 0.9378 - val_loss: 0.1599 - val_accuracy: 0.9745\n",
            "Epoch 57/300\n",
            "784/784 [==============================] - 4s 6ms/step - loss: 0.1473 - accuracy: 0.9380 - val_loss: 0.1432 - val_accuracy: 0.9624\n",
            "Epoch 58/300\n",
            "624/784 [======================>.......] - ETA: 1s - loss: 0.1676 - accuracy: 0.9291"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/nasaq_2_5_save.h5\")\n",
        "# model = tf.keras.models.load_model(\"best_model.h5\")\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "jqRgrzZg084k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for stock in [\"AMZN\"]:\n",
        "  predictions = []\n",
        "\n",
        "  stock_data = yf.download(stock, start=\"2022-01-01\", end=\"2023-08-10\", progress=False)\n",
        "  stock_data = create_indicators(stock_data)\n",
        "\n",
        "  stock_data[\"signal\"] = 0\n",
        "\n",
        "  for row in range(stock_data.shape[0]):\n",
        "    if row+1 != stock_data.shape[0] and stock_data[\"Close\"].iloc[row+1] > stock_data[\"Close\"].iloc[row] + 5*(stock_data[\"Close\"].iloc[row])/100:\n",
        "      stock_data[\"signal\"].iloc[row] = 1\n",
        "\n",
        "  stock_data = stock_data.drop([\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"], axis=1)\n",
        "\n",
        "  for index, row in stock_data.iterrows():\n",
        "      x = row[1:34]\n",
        "\n",
        "      new_data = x.to_numpy().reshape(1, -1)\n",
        "      new_data = scaler.transform(new_data)\n",
        "      prediction = model.predict(new_data, verbose=None)\n",
        "\n",
        "      print(f\"Prediction for date {row[0]}: {np.round(prediction[0][0])}\")\n",
        "\n",
        "      if np.round(prediction[0][0]) == row[\"signal\"]:\n",
        "        predictions.append(1)\n",
        "      elif np.round(prediction[0][0]) != row[\"signal\"]:\n",
        "        predictions.append(0)\n",
        "\n",
        "  print(f\"{stock} Accuracy: {predictions.count(1) / len(predictions) * 100}\")"
      ],
      "metadata": {
        "id": "GXskMvribBZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buy_stocks = []\n",
        "\n",
        "for stock in nasdaq100:\n",
        "  stock_data = yf.download(stock, start=\"2021-06-01\", end=\"2023-08-14\", progress=False)\n",
        "  stock_data = create_indicators(stock_data)\n",
        "  stock_data = stock_data.drop([\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"], axis=1)\n",
        "\n",
        "  x = stock_data.tail(1)[:33]\n",
        "\n",
        "  new_data = x.to_numpy().reshape(1, -1)\n",
        "  new_data = scaler.transform(new_data)\n",
        "  prediction = model.predict(new_data, verbose=None)\n",
        "\n",
        "  buy_stocks.append([stock, round(prediction[0][0]*100,2)])\n",
        "\n",
        "pd.DataFrame(buy_stocks, columns=[\"stock\", \"probability\"]).sort_values(by=\"probability\", ascending=False).head(20)"
      ],
      "metadata": {
        "id": "YASh8fggUiZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8cj_wIP3pJMF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNYQa/8eIptquMv353MIOzv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erendagasan/Eren-Dagasan-Personal/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q bta-lib\n",
        "!pip install -q ta\n",
        "\n",
        "import btalib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ta.trend import PSARIndicator\n",
        "from ta.momentum import WilliamsRIndicator\n",
        "from ta.trend import AroonIndicator\n",
        "from ta.volume import VolumePriceTrendIndicator\n",
        "from ta.trend import CCIIndicator\n",
        "from ta.momentum import ROCIndicator\n",
        "from ta.trend import ADXIndicator\n",
        "import yfinance as yf\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "def create_indicators(data):\n",
        "  data[\"RSI\"] = btalib.rsi(data[\"Close\"], period=14).df\n",
        "  data[\"SMA5\"] = btalib.sma(data['Close'], period=5).df\n",
        "  data[\"SMA9\"] = btalib.sma(data['Close'], period=9).df\n",
        "  data[\"SMA10\"] = btalib.sma(data['Close'], period=10).df\n",
        "  data[\"SMA14\"] = btalib.sma(data['Close'], period=14).df\n",
        "  data[\"SMA20\"] = btalib.sma(data['Close'], period=20).df\n",
        "  data[\"SMA21\"] = btalib.sma(data['Close'], period=21).df\n",
        "  data[\"SMA50\"] = btalib.sma(data['Close'], period=50).df\n",
        "  data[\"SMA200\"] = btalib.sma(data['Close'], period=200).df\n",
        "  data[\"EMA5\"] = btalib.ema(data['Close'], period=5).df\n",
        "  data[\"EMA14\"] = btalib.ema(data['Close'], period=14).df\n",
        "  data[\"EMA21\"] = btalib.ema(data['Close'], period=21).df\n",
        "  data[\"EMA50\"] = btalib.ema(data['Close'], period=50).df\n",
        "  data[\"STOCH-K\"] = btalib.stoch(data['High'], data['Low'], data['Close']).df[\"k\"]\n",
        "  data[\"STOCH-D\"] = btalib.stoch(data['High'], data['Low'], data['Close']).df[\"d\"]\n",
        "  data[\"MACD\"] = btalib.macd(data['Close']).df[\"macd\"]\n",
        "  data[\"SIGNAL\"] = btalib.macd(data['Close']).df[\"signal\"]\n",
        "  data[\"HISTOGRAM\"] = btalib.macd(data['Close']).df[\"histogram\"]\n",
        "  data[\"BB-UPPER\"] = btalib.bbands(data['Close']).df['top']\n",
        "  data[\"BB-MID\"] = btalib.bbands(data['Close']).df['mid']\n",
        "  data[\"BB-LOWER\"] = btalib.bbands(data['Close']).df['bot']\n",
        "  data[\"STDEV\"] = data[\"Close\"].rolling(window=10).std()\n",
        "  data[\"PSAR\"] = PSARIndicator(data[\"High\"], data[\"Low\"], data[\"Close\"]).psar()\n",
        "  data[\"WILLIAMS\"] = WilliamsRIndicator(data[\"High\"], data[\"Low\"], data[\"Close\"]).williams_r()\n",
        "  data[\"AROON\"] = AroonIndicator(close=data[\"Close\"], window=25).aroon_indicator()\n",
        "  data[\"OBV\"] = VolumePriceTrendIndicator(close=data['Close'], volume=data['Volume']).volume_price_trend()\n",
        "  data['CCI'] = CCIIndicator(close=data['Close'], low=data[\"Low\"], high=data[\"High\"], window=14).cci()\n",
        "  data['ROC'] = ROCIndicator(close=data['Close'], window=5).roc()\n",
        "  data['BULL'] = data['High'] - (data['High'].rolling(13).max() + data['Low'].rolling(13).min()) / 2\n",
        "  data['BEAR'] = data['Low'] - (data['High'].rolling(13).max() + data['Low'].rolling(13).min()) / 2\n",
        "  adx_indicator = ADXIndicator(high=data['High'], low=data['Low'], close=data['Close'], window=14)\n",
        "  data['ADX'] = adx_indicator.adx()\n",
        "  data['+DI'] = adx_indicator.adx_pos()\n",
        "  data['-DI'] = adx_indicator.adx_neg()\n",
        "\n",
        "  data = data.dropna()\n",
        "  data = data.reset_index()\n",
        "  return data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfv1WZ9SIIPB",
        "outputId": "1b0e3247-fdfb-442a-fe04-108965ad7a23"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/92.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/92.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYS1wHF8FcB9"
      },
      "outputs": [],
      "source": [
        "# sheet_id = \"1RSqOXkFTAO7g4H9LEY3d3IX6H6bJaYk1\"\n",
        "# sheet_name = \"Sheet_1\"\n",
        "# url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "# result_df = pd.read_csv(url)\n",
        "\n",
        "sheet_id = \"1AA9MfqOtAAgO97__aomD79DciyT-PkRQ\"\n",
        "sheet_name = \"Sheet_1\"\n",
        "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "result_df = pd.read_csv(url)\n",
        "\n",
        "data = pd.DataFrame()\n",
        "\n",
        "for stock in result_df[\"STOCK\"].unique():\n",
        "  print(stock)\n",
        "  stock_data = yf.download(stock, start=\"2000-01-01\", end=\"2023-08-08\", progress=False)\n",
        "  stock_data = create_indicators(stock_data)\n",
        "\n",
        "  stock_data[\"signal\"] = 0\n",
        "\n",
        "  for row in range(stock_data.shape[0]):\n",
        "    if row+1 != stock_data.shape[0] and stock_data[\"Close\"].iloc[row+1] > stock_data[\"Close\"].iloc[row] + 5*(stock_data[\"Close\"].iloc[row])/100:\n",
        "      stock_data[\"signal\"].iloc[row] = 1\n",
        "\n",
        "\n",
        "  stock_data = stock_data.drop([\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"], axis=1)\n",
        "  data = pd.concat([data, stock_data], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "qFzpmolvcpCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[data[\"signal\"] == 1]"
      ],
      "metadata": {
        "id": "R7VTJgSzaIXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "input_columns = df.columns[:34]\n",
        "output_column = \"signal\"\n",
        "\n",
        "df[output_column] = df[output_column].astype(int)\n",
        "\n",
        "X = df[input_columns].values\n",
        "y = df[output_column].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Input(shape=(X_train_resampled.shape[1],)),\n",
        "#     tf.keras.layers.Dense(256, activation='relu'),\n",
        "#     tf.keras.layers.Dropout(0.3),\n",
        "#     tf.keras.layers.Dense(128, activation='relu'),\n",
        "#     tf.keras.layers.Dropout(0.3),\n",
        "#     tf.keras.layers.Dense(64, activation='relu'),\n",
        "#     tf.keras.layers.Dropout(0.3),\n",
        "#     tf.keras.layers.BatchNormalization(),\n",
        "#     tf.keras.layers.Dense(32, activation='relu'),\n",
        "#     tf.keras.layers.Dropout(0.3),\n",
        "#     tf.keras.layers.Dense(16, activation='relu'),\n",
        "#     tf.keras.layers.Dropout(0.3),\n",
        "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train_resampled.shape[1], 1)),  # Add the input shape with 1 time step\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),  # Return sequences for stacking LSTM layers\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.LSTM(32),  # Second LSTM layer without returning sequences\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=256, validation_split=0.2)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "f1 = f1_score(y_test, y_pred_binary)\n",
        "print(f\"F1-score on test data: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "IfSHE91eZonR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 2\n",
        "new_data = X_test[index].reshape(1,-1)\n",
        "\n",
        "new_data = scaler.transform(new_data)\n",
        "prediction = model.predict(new_data)\n",
        "\n",
        "print(f\"Prediction: {prediction[0][0]:.4f} => {y_test[index]}\")"
      ],
      "metadata": {
        "id": "vym-Yb_BZp3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_data = yf.download(\"CMENT.IS\", start=\"2000-01-01\", end=\"2023-08-08\")\n",
        "stock_data = create_indicators(stock_data)\n",
        "\n",
        "stock_data[\"signal\"] = 0\n",
        "\n",
        "for row in range(stock_data.shape[0]):\n",
        "  if row+1 != stock_data.shape[0] and stock_data[\"Close\"].iloc[row+1] > stock_data[\"Close\"].iloc[row] + 10*(stock_data[\"Close\"].iloc[row])/100:\n",
        "    stock_data[\"signal\"].iloc[row] = 1\n",
        "\n",
        "stock_data = stock_data.drop([\"Open\", \"High\", \"Low\", \"Adj Close\", \"Volume\"], axis=1)\n",
        "tens = stock_data[stock_data[\"signal\"] == 1]\n",
        "\n",
        "for index, row in tens.iterrows():\n",
        "    x = row[2:36]\n",
        "\n",
        "    new_data = x.to_numpy().reshape(1, -1)\n",
        "\n",
        "    new_data = scaler.transform(new_data)\n",
        "    prediction = model.predict(new_data)\n",
        "\n",
        "    print(f\"{row[0]} - Prediction for row {index}: {np.round(prediction[0][0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXskMvribBZo",
        "outputId": "860961b5-6cd5-4e9a-8bd4-c4734f64039e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2001-05-17 00:00:00 - Prediction for row 7: 1.0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2001-05-31 00:00:00 - Prediction for row 13: 1.0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2001-06-07 00:00:00 - Prediction for row 17: 1.0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2002-01-21 00:00:00 - Prediction for row 145: 1.0\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2002-10-02 00:00:00 - Prediction for row 308: 1.0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2002-11-01 00:00:00 - Prediction for row 329: 1.0\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2003-12-19 00:00:00 - Prediction for row 606: 1.0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2004-10-12 00:00:00 - Prediction for row 810: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2004-10-13 00:00:00 - Prediction for row 811: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2005-02-25 00:00:00 - Prediction for row 900: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2005-08-19 00:00:00 - Prediction for row 1024: 1.0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2005-08-22 00:00:00 - Prediction for row 1025: 1.0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2005-10-03 00:00:00 - Prediction for row 1054: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2006-05-25 00:00:00 - Prediction for row 1215: 1.0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2006-07-31 00:00:00 - Prediction for row 1262: 1.0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2006-08-01 00:00:00 - Prediction for row 1263: 1.0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2006-11-21 00:00:00 - Prediction for row 1338: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2008-03-28 00:00:00 - Prediction for row 1676: 1.0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2009-02-24 00:00:00 - Prediction for row 1901: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2009-03-20 00:00:00 - Prediction for row 1919: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2009-03-23 00:00:00 - Prediction for row 1920: 1.0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2009-06-17 00:00:00 - Prediction for row 1980: 1.0\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2009-06-18 00:00:00 - Prediction for row 1981: 1.0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2009-06-23 00:00:00 - Prediction for row 1984: 1.0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2009-10-12 00:00:00 - Prediction for row 2061: 1.0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2009-11-19 00:00:00 - Prediction for row 2088: 1.0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2009-12-18 00:00:00 - Prediction for row 2107: 1.0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2009-12-24 00:00:00 - Prediction for row 2111: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2011-01-18 00:00:00 - Prediction for row 2380: 1.0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2011-03-21 00:00:00 - Prediction for row 2424: 1.0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2012-03-06 00:00:00 - Prediction for row 2674: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2012-03-07 00:00:00 - Prediction for row 2675: 1.0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2012-03-08 00:00:00 - Prediction for row 2676: 1.0\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2014-11-17 00:00:00 - Prediction for row 3378: 1.0\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2015-03-06 00:00:00 - Prediction for row 3457: 1.0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2015-03-09 00:00:00 - Prediction for row 3458: 1.0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2015-07-01 00:00:00 - Prediction for row 3540: 1.0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2017-02-15 00:00:00 - Prediction for row 3965: 1.0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2017-03-07 00:00:00 - Prediction for row 3979: 1.0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2017-03-14 00:00:00 - Prediction for row 3984: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2017-07-14 00:00:00 - Prediction for row 4072: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2017-07-17 00:00:00 - Prediction for row 4073: 1.0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2018-12-20 00:00:00 - Prediction for row 4446: 1.0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2018-12-21 00:00:00 - Prediction for row 4447: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2018-12-27 00:00:00 - Prediction for row 4451: 1.0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2019-03-20 00:00:00 - Prediction for row 4510: 1.0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2019-03-21 00:00:00 - Prediction for row 4511: 1.0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2019-04-10 00:00:00 - Prediction for row 4525: 1.0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2019-05-28 00:00:00 - Prediction for row 4559: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2019-11-06 00:00:00 - Prediction for row 4674: 1.0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2020-03-31 00:00:00 - Prediction for row 4777: 1.0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2020-05-12 00:00:00 - Prediction for row 4805: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2020-05-18 00:00:00 - Prediction for row 4809: 1.0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2020-07-17 00:00:00 - Prediction for row 4849: 1.0\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2020-09-07 00:00:00 - Prediction for row 4883: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2020-09-15 00:00:00 - Prediction for row 4889: 1.0\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2020-11-11 00:00:00 - Prediction for row 4929: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2020-12-30 00:00:00 - Prediction for row 4964: 1.0\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2021-01-12 00:00:00 - Prediction for row 4972: 1.0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2022-11-30 00:00:00 - Prediction for row 5444: 1.0\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "2023-02-08 00:00:00 - Prediction for row 5494: 1.0\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2023-08-03 00:00:00 - Prediction for row 5610: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"XUTUM-%10.h5\")"
      ],
      "metadata": {
        "id": "jqRgrzZg084k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erendagasan/Eren-Dagasan-Personal/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Libraries and Indicator Function\n",
        "\n",
        "!pip install -q bta-lib\n",
        "!pip install -q ta\n",
        "\n",
        "import btalib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ta.trend import PSARIndicator\n",
        "from ta.momentum import WilliamsRIndicator\n",
        "from ta.trend import AroonIndicator\n",
        "from ta.volume import VolumePriceTrendIndicator\n",
        "from ta.trend import CCIIndicator\n",
        "from ta.momentum import ROCIndicator\n",
        "from ta.trend import ADXIndicator\n",
        "import yfinance as yf\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.metrics import f1_score\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "def create_indicators(data):\n",
        "  data[\"RSI\"] = btalib.rsi(data[\"Close\"], period=14).df\n",
        "  data[\"SMA5\"] = btalib.sma(data['Close'], period=5).df\n",
        "  data[\"SMA9\"] = btalib.sma(data['Close'], period=9).df\n",
        "  data[\"SMA10\"] = btalib.sma(data['Close'], period=10).df\n",
        "  data[\"SMA14\"] = btalib.sma(data['Close'], period=14).df\n",
        "  data[\"SMA20\"] = btalib.sma(data['Close'], period=20).df\n",
        "  data[\"SMA21\"] = btalib.sma(data['Close'], period=21).df\n",
        "  data[\"SMA50\"] = btalib.sma(data['Close'], period=50).df\n",
        "  data[\"SMA200\"] = btalib.sma(data['Close'], period=200).df\n",
        "  data[\"EMA5\"] = btalib.ema(data['Close'], period=5).df\n",
        "  data[\"EMA14\"] = btalib.ema(data['Close'], period=14).df\n",
        "  data[\"EMA21\"] = btalib.ema(data['Close'], period=21).df\n",
        "  data[\"EMA50\"] = btalib.ema(data['Close'], period=50).df\n",
        "  data[\"STOCH-K\"] = btalib.stoch(data['High'], data['Low'], data['Close']).df[\"k\"]\n",
        "  data[\"STOCH-D\"] = btalib.stoch(data['High'], data['Low'], data['Close']).df[\"d\"]\n",
        "  data[\"MACD\"] = btalib.macd(data['Close']).df[\"macd\"]\n",
        "  data[\"SIGNAL\"] = btalib.macd(data['Close']).df[\"signal\"]\n",
        "  data[\"HISTOGRAM\"] = btalib.macd(data['Close']).df[\"histogram\"]\n",
        "  data[\"BB-UPPER\"] = btalib.bbands(data['Close']).df['top']\n",
        "  data[\"BB-MID\"] = btalib.bbands(data['Close']).df['mid']\n",
        "  data[\"BB-LOWER\"] = btalib.bbands(data['Close']).df['bot']\n",
        "  data[\"STDEV\"] = data[\"Close\"].rolling(window=10).std()\n",
        "  data[\"PSAR\"] = PSARIndicator(data[\"High\"], data[\"Low\"], data[\"Close\"]).psar()\n",
        "  data[\"WILLIAMS\"] = WilliamsRIndicator(data[\"High\"], data[\"Low\"], data[\"Close\"]).williams_r()\n",
        "  data[\"AROON\"] = AroonIndicator(close=data[\"Close\"], window=25).aroon_indicator()\n",
        "  data[\"OBV\"] = VolumePriceTrendIndicator(close=data['Close'], volume=data['Volume']).volume_price_trend()\n",
        "  data['CCI'] = CCIIndicator(close=data['Close'], low=data[\"Low\"], high=data[\"High\"], window=14).cci()\n",
        "  data['ROC'] = ROCIndicator(close=data['Close'], window=5).roc()\n",
        "  data['BULL'] = data['High'] - (data['High'].rolling(13).max() + data['Low'].rolling(13).min()) / 2\n",
        "  data['BEAR'] = data['Low'] - (data['High'].rolling(13).max() + data['Low'].rolling(13).min()) / 2\n",
        "  adx_indicator = ADXIndicator(high=data['High'], low=data['Low'], close=data['Close'], window=14)\n",
        "  data['ADX'] = adx_indicator.adx()\n",
        "  data['+DI'] = adx_indicator.adx_pos()\n",
        "  data['-DI'] = adx_indicator.adx_neg()\n",
        "\n",
        "  data = data.dropna()\n",
        "  data = data.reset_index()\n",
        "  return data"
      ],
      "metadata": {
        "id": "Lfv1WZ9SIIPB",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYS1wHF8FcB9"
      },
      "outputs": [],
      "source": [
        "# sheet_id = \"1RSqOXkFTAO7g4H9LEY3d3IX6H6bJaYk1\"\n",
        "# sheet_name = \"Sheet_1\"\n",
        "# url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "# result_df = pd.read_csv(url)\n",
        "\n",
        "sheet_id = \"1AA9MfqOtAAgO97__aomD79DciyT-PkRQ\"\n",
        "sheet_name = \"Sheet_1\"\n",
        "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "result_df = pd.read_csv(url)\n",
        "\n",
        "data = pd.DataFrame()\n",
        "\n",
        "for stock in result_df[\"STOCK\"].unique():\n",
        "  print(stock)\n",
        "  stock_data = yf.download(stock, start=\"2000-01-01\", end=\"2023-08-08\", progress=False)\n",
        "  stock_data = create_indicators(stock_data)\n",
        "\n",
        "  stock_data[\"signal\"] = 0\n",
        "\n",
        "  for row in range(stock_data.shape[0]):\n",
        "    if row+1 != stock_data.shape[0] and stock_data[\"Close\"].iloc[row+1] > stock_data[\"Close\"].iloc[row] + 5*(stock_data[\"Close\"].iloc[row])/100:\n",
        "      stock_data[\"signal\"].iloc[row] = 1\n",
        "\n",
        "\n",
        "  stock_data = stock_data.drop([\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"], axis=1)\n",
        "  data = pd.concat([data, stock_data], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "qFzpmolvcpCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[data[\"signal\"] == 1]"
      ],
      "metadata": {
        "id": "R7VTJgSzaIXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data)\n",
        "\n",
        "input_columns = df.columns[:33]\n",
        "output_column = \"signal\"\n",
        "\n",
        "df[output_column] = df[output_column].astype(int)\n",
        "\n",
        "X = df[input_columns].values\n",
        "y = df[output_column].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Input(shape=(X_train_resampled.shape[1],)),\n",
        "#     tf.keras.layers.Dense(256, activation='relu'),\n",
        "#     tf.keras.layers.Dropout(0.3),\n",
        "#     tf.keras.layers.Dense(128, activation='relu'),\n",
        "#     tf.keras.layers.Dropout(0.3),\n",
        "#     tf.keras.layers.Dense(64, activation='relu'),\n",
        "#     tf.keras.layers.Dropout(0.3),\n",
        "#     tf.keras.layers.BatchNormalization(),\n",
        "#     tf.keras.layers.Dense(32, activation='relu'),\n",
        "#     tf.keras.layers.Dropout(0.3),\n",
        "#     tf.keras.layers.Dense(16, activation='relu'),\n",
        "#     tf.keras.layers.Dropout(0.3),\n",
        "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train_resampled.shape[1], 1)),  # Add the input shape with 1 time step\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),  # Return sequences for stacking LSTM layers\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.LSTM(32),  # Second LSTM layer without returning sequences\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_resampled, y_train_resampled, epochs=500, batch_size=128, validation_split=0.2)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "f1 = f1_score(y_test, y_pred_binary)\n",
        "print(f\"F1-score on test data: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "IfSHE91eZonR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"xu030_model_five_percent_600.h5\")\n",
        "# model.load(\"xu030_model_five_percent_600.h5\")"
      ],
      "metadata": {
        "id": "jqRgrzZg084k"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 10\n",
        "new_data = X_test[index].reshape(1,-1)\n",
        "\n",
        "new_data = scaler.transform(new_data)\n",
        "prediction = model.predict(new_data)\n",
        "\n",
        "print(f\"Prediction: {prediction[0][0]:.4f} => {y_test[index]}\")"
      ],
      "metadata": {
        "id": "vym-Yb_BZp3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_data = yf.download(\"YKBNK.IS\", start=\"2000-01-01\", end=\"2023-08-08\", progress=False)\n",
        "stock_data = create_indicators(stock_data)\n",
        "\n",
        "stock_data[\"signal\"] = 0\n",
        "\n",
        "for row in range(stock_data.shape[0]):\n",
        "  if row+1 != stock_data.shape[0] and stock_data[\"Close\"].iloc[row+1] > stock_data[\"Close\"].iloc[row] + 10*(stock_data[\"Close\"].iloc[row])/100:\n",
        "    stock_data[\"signal\"].iloc[row] = 1\n",
        "\n",
        "stock_data = stock_data.drop([\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"], axis=1)\n",
        "tens = stock_data[stock_data[\"signal\"] == 1]\n",
        "\n",
        "for index, row in tens.iterrows():\n",
        "    x = row[1:34]\n",
        "\n",
        "    new_data = x.to_numpy().reshape(1, -1)\n",
        "\n",
        "    new_data = scaler.transform(new_data)\n",
        "    prediction = model.predict(new_data, verbose=None)\n",
        "\n",
        "    print(f\"Prediction for date {row[0]}: {np.round(prediction[0][0])}\")"
      ],
      "metadata": {
        "id": "GXskMvribBZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db3beb78-2084-4e97-e4d3-abe05384aefa"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for date 2001-04-05 00:00:00: 1.0\n",
            "Prediction for date 2001-04-26 00:00:00: 1.0\n",
            "Prediction for date 2001-04-27 00:00:00: 1.0\n",
            "Prediction for date 2001-05-03 00:00:00: 1.0\n",
            "Prediction for date 2001-05-31 00:00:00: 0.0\n",
            "Prediction for date 2001-06-07 00:00:00: 1.0\n",
            "Prediction for date 2001-07-09 00:00:00: 1.0\n",
            "Prediction for date 2001-07-24 00:00:00: 1.0\n",
            "Prediction for date 2001-08-06 00:00:00: 1.0\n",
            "Prediction for date 2002-01-30 00:00:00: 1.0\n",
            "Prediction for date 2002-06-26 00:00:00: 1.0\n",
            "Prediction for date 2002-06-27 00:00:00: 1.0\n",
            "Prediction for date 2002-10-18 00:00:00: 1.0\n",
            "Prediction for date 2002-11-01 00:00:00: 0.0\n",
            "Prediction for date 2002-11-04 00:00:00: 1.0\n",
            "Prediction for date 2002-11-06 00:00:00: 1.0\n",
            "Prediction for date 2003-01-24 00:00:00: 1.0\n",
            "Prediction for date 2003-10-02 00:00:00: 1.0\n",
            "Prediction for date 2003-10-03 00:00:00: 1.0\n",
            "Prediction for date 2003-12-12 00:00:00: 1.0\n",
            "Prediction for date 2004-01-02 00:00:00: 1.0\n",
            "Prediction for date 2004-03-26 00:00:00: 1.0\n",
            "Prediction for date 2004-06-03 00:00:00: 1.0\n",
            "Prediction for date 2005-01-19 00:00:00: 1.0\n",
            "Prediction for date 2006-06-27 00:00:00: 1.0\n",
            "Prediction for date 2008-09-18 00:00:00: 1.0\n",
            "Prediction for date 2008-10-27 00:00:00: 1.0\n",
            "Prediction for date 2008-10-28 00:00:00: 1.0\n",
            "Prediction for date 2008-11-21 00:00:00: 1.0\n",
            "Prediction for date 2009-05-06 00:00:00: 1.0\n",
            "Prediction for date 2015-10-30 00:00:00: 0.0\n",
            "Prediction for date 2017-01-27 00:00:00: 0.0\n",
            "Prediction for date 2020-11-17 00:00:00: 1.0\n",
            "Prediction for date 2023-02-08 00:00:00: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "buy_stocks = []\n",
        "\n",
        "for stock in result_df[\"STOCK\"].unique():\n",
        "  stock_data = yf.download(stock, start=\"2021-01-01\", end=\"2023-08-08\", progress=False)\n",
        "  stock_data = create_indicators(stock_data)\n",
        "  stock_data = stock_data.drop([\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"], axis=1)\n",
        "\n",
        "  x = stock_data.tail(1)[:33]\n",
        "\n",
        "  new_data = x.to_numpy().reshape(1, -1)\n",
        "\n",
        "  new_data = scaler.transform(new_data)\n",
        "  prediction = model.predict(new_data, verbose=None)\n",
        "\n",
        "  if np.round(prediction[0][0]) == 1:\n",
        "    buy_stocks.append(stock)\n",
        "\n",
        "buy_stocks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YASh8fggUiZk",
        "outputId": "f45e693f-4211-4bf0-f68e-d8b47c97405d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TAVHL.IS']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jGfiMdc_mufL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erendagasan/Eren-Dagasan-Personal/blob/main/deneme_untitled_0_best_model_2_from_drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Libraries and Indicator Function\n",
        "\n",
        "!pip install -q bta-lib\n",
        "!pip install -q ta\n",
        "\n",
        "import btalib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ta.trend import PSARIndicator\n",
        "from ta.momentum import WilliamsRIndicator\n",
        "from ta.trend import AroonIndicator\n",
        "from ta.volume import VolumePriceTrendIndicator\n",
        "from ta.trend import CCIIndicator\n",
        "from ta.momentum import ROCIndicator\n",
        "from ta.trend import ADXIndicator\n",
        "import yfinance as yf\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "def create_indicators(data):\n",
        "  data[\"RSI\"] = btalib.rsi(data[\"Close\"], period=14).df\n",
        "  data[\"SMA5\"] = btalib.sma(data['Close'], period=5).df\n",
        "  data[\"SMA9\"] = btalib.sma(data['Close'], period=9).df\n",
        "  data[\"SMA10\"] = btalib.sma(data['Close'], period=10).df\n",
        "  data[\"SMA14\"] = btalib.sma(data['Close'], period=14).df\n",
        "  data[\"SMA20\"] = btalib.sma(data['Close'], period=20).df\n",
        "  data[\"SMA21\"] = btalib.sma(data['Close'], period=21).df\n",
        "  data[\"SMA50\"] = btalib.sma(data['Close'], period=50).df\n",
        "  data[\"SMA200\"] = btalib.sma(data['Close'], period=200).df\n",
        "  data[\"EMA5\"] = btalib.ema(data['Close'], period=5).df\n",
        "  data[\"EMA14\"] = btalib.ema(data['Close'], period=14).df\n",
        "  data[\"EMA21\"] = btalib.ema(data['Close'], period=21).df\n",
        "  data[\"EMA50\"] = btalib.ema(data['Close'], period=50).df\n",
        "  data[\"STOCH-K\"] = btalib.stoch(data['High'], data['Low'], data['Close']).df[\"k\"]\n",
        "  data[\"STOCH-D\"] = btalib.stoch(data['High'], data['Low'], data['Close']).df[\"d\"]\n",
        "  data[\"MACD\"] = btalib.macd(data['Close']).df[\"macd\"]\n",
        "  data[\"SIGNAL\"] = btalib.macd(data['Close']).df[\"signal\"]\n",
        "  data[\"HISTOGRAM\"] = btalib.macd(data['Close']).df[\"histogram\"]\n",
        "  data[\"BB-UPPER\"] = btalib.bbands(data['Close']).df['top']\n",
        "  data[\"BB-MID\"] = btalib.bbands(data['Close']).df['mid']\n",
        "  data[\"BB-LOWER\"] = btalib.bbands(data['Close']).df['bot']\n",
        "  data[\"STDEV\"] = data[\"Close\"].rolling(window=10).std()\n",
        "  data[\"PSAR\"] = PSARIndicator(data[\"High\"], data[\"Low\"], data[\"Close\"]).psar()\n",
        "  data[\"WILLIAMS\"] = WilliamsRIndicator(data[\"High\"], data[\"Low\"], data[\"Close\"]).williams_r()\n",
        "  data[\"AROON\"] = AroonIndicator(close=data[\"Close\"], window=25).aroon_indicator()\n",
        "  data[\"OBV\"] = VolumePriceTrendIndicator(close=data['Close'], volume=data['Volume']).volume_price_trend()\n",
        "  data['CCI'] = CCIIndicator(close=data['Close'], low=data[\"Low\"], high=data[\"High\"], window=14).cci()\n",
        "  data['ROC'] = ROCIndicator(close=data['Close'], window=5).roc()\n",
        "  data['BULL'] = data['High'] - (data['High'].rolling(13).max() + data['Low'].rolling(13).min()) / 2\n",
        "  data['BEAR'] = data['Low'] - (data['High'].rolling(13).max() + data['Low'].rolling(13).min()) / 2\n",
        "  adx_indicator = ADXIndicator(high=data['High'], low=data['Low'], close=data['Close'], window=14)\n",
        "  data['ADX'] = adx_indicator.adx()\n",
        "  data['+DI'] = adx_indicator.adx_pos()\n",
        "  data['-DI'] = adx_indicator.adx_neg()\n",
        "\n",
        "  data = data.dropna()\n",
        "  data = data.reset_index()\n",
        "  return data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Lfv1WZ9SIIPB",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5df6b01-5ebe-40d1-eaac-391beb7988be"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/92.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/92.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the Model\n",
        "\n",
        "import gdown\n",
        "\n",
        "# gdown.download(\"https://drive.google.com/u/1/uc?id=1qWKIj9rzRzyW3GQFw9xISs4eXmjyIDng&export=download\", \"/content/\", quiet=False)\n",
        "# gdown.download(\"https://drive.google.com/u/0/uc?id=117pezAA6jRLCwIsdpEhZgEa9tEanlC0O&export=download\", \"/content/\", quiet=False)\n",
        "\n",
        "data = pd.read_csv(\"data.csv\")\n",
        "model = tf.keras.models.load_model(\"best_model.h5\")"
      ],
      "metadata": {
        "id": "j0_ac_MyLUax",
        "cellView": "form"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Stock List\n",
        "sheet_id = \"1RSqOXkFTAO7g4H9LEY3d3IX6H6bJaYk1\"\n",
        "sheet_name = \"Sheet_1\"\n",
        "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "result_df = pd.read_csv(url)\n",
        "\n",
        "sheet_id = \"1AA9MfqOtAAgO97__aomD79DciyT-PkRQ\"\n",
        "sheet_name = \"Sheet_1\"\n",
        "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "result_df = pd.read_csv(url)\n",
        "\n",
        "nasdaq100 = ['AAPL', 'MSFT', 'GOOGL', 'GOOG', 'AMZN',\n",
        "             'NVDA', 'TSLA', 'META', 'AVGO', 'ASML',\n",
        "             'PEP', 'COST', 'ADBE', 'AZN', 'CSCO',\n",
        "             'NFLX', 'AMD', 'CMCSA', 'TMUS', 'TXN',\n",
        "             'QCOM', 'HON', 'INTU', 'INTC', 'SNY',\n",
        "             'VZ', 'AMGN', 'SBUX', 'ISRG', 'AMAT',\n",
        "             'BKNG', 'ADI', 'MDLZ', 'PDD', 'GILD',\n",
        "             'ADP', 'VRTX', 'ABNB', 'LRCX', 'PYPL',\n",
        "             'REGN', 'EQIX', 'MU', 'CSX', 'SNPS',\n",
        "             'CME', 'CDNS', 'KLAC', 'NTES']"
      ],
      "metadata": {
        "id": "3g0KHl4YMTKd",
        "cellView": "form"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame()\n",
        "\n",
        "for stock in result_df[\"STOCK\"].unique():\n",
        "  stock_df = yf.download(stock, start=\"2000-01-01\", end=\"2023-01-01\", progress=False)\n",
        "  stock_df = create_indicators(stock_df)\n",
        "  stock_df[\"signal\"] = 0\n",
        "\n",
        "  for index, row in stock_df.iterrows():\n",
        "    if index > 0 and index < stock_df.shape[0]-1 and stock_df[\"Close\"].iloc[index+1] > ((2.5*stock_df[\"Close\"].iloc[index]/100) + stock_df[\"Close\"].iloc[index]):\n",
        "      stock_df[\"signal\"].iloc[index] = 1\n",
        "\n",
        "  stock_df = stock_df.drop([\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Adj Close\"], axis=1)\n",
        "\n",
        "  data = pd.concat([data, stock_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "301D-_cbzUbS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Preprocessing\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "input_columns = df.columns[:33]\n",
        "output_column = \"signal\"\n",
        "\n",
        "df[output_column] = df[output_column].astype(int)\n",
        "\n",
        "X = df[input_columns].values\n",
        "y = df[output_column].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight(\"balanced\", classes=[0, 1], y=y_train)\n",
        "class_weight = {cls: weight for cls, weight in zip([0, 1], class_weights)}\n",
        "class_weight"
      ],
      "metadata": {
        "id": "K-Gz1pgOMh8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8abb25b6-4c5d-4cdc-8ed6-ca33d74b6aa2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.5752297447063093, 1: 3.823153640571019}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LSTM Model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train_resampled.shape[1], 1)),\n",
        "\n",
        "    tf.keras.layers.LSTM(512, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.LSTM(512, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.LSTM(256),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
        "\n",
        "model.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=256, validation_split=0.2, callbacks=[early_stopping, model_checkpoint])"
      ],
      "metadata": {
        "id": "IfSHE91eZonR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Conv1D model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "X_train_resampled = np.expand_dims(X_train_resampled, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "def create_model():\n",
        "    input_layer = keras.Input(shape=(X_train_resampled.shape[1], X_train_resampled.shape[2]))\n",
        "\n",
        "    x = layers.Conv1D(\n",
        "        filters=32, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\"\n",
        "    )(input_layer)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv1D(\n",
        "        filters=64, kernel_size=3, strides=2, activation=\"relu\", padding=\"same\"\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv1D(\n",
        "        filters=128, kernel_size=5, strides=2, activation=\"relu\", padding=\"same\"\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv1D(\n",
        "        filters=256, kernel_size=5, strides=2, activation=\"relu\", padding=\"same\"\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv1D(\n",
        "        filters=512, kernel_size=7, strides=2, activation=\"relu\", padding=\"same\"\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv1D(\n",
        "        filters=1024, kernel_size=7, strides=2, activation=\"relu\", padding=\"same\"\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    x = layers.Dense(4096, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Dense(\n",
        "        2048, activation=\"relu\", kernel_regularizer=keras.regularizers.L2()\n",
        "    )(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    x = layers.Dense(\n",
        "        1024, activation=\"relu\", kernel_regularizer=keras.regularizers.L2()\n",
        "    )(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(\n",
        "        128, activation=\"relu\", kernel_regularizer=keras.regularizers.L2()\n",
        "    )(x)\n",
        "    output_layer = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/best_model_2.h5', save_best_only=False)\n",
        "\n",
        "model.fit(X_train_resampled, y_train_resampled, epochs=200, batch_size=512, validation_split=0.2,\n",
        "          callbacks=[early_stopping, model_checkpoint], class_weight=class_weight)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "J1wt4y6SAmBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "571f225e-0987-4a4c-a39d-8ed7ee69ce07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "319/319 [==============================] - 38s 94ms/step - loss: 3.6090 - accuracy: 0.3753 - val_loss: 0.3291 - val_accuracy: 1.0000\n",
            "Epoch 2/200\n",
            "319/319 [==============================] - 34s 105ms/step - loss: 0.8959 - accuracy: 0.3750 - val_loss: 0.2382 - val_accuracy: 1.0000\n",
            "Epoch 3/200\n",
            "319/319 [==============================] - 38s 120ms/step - loss: 0.8761 - accuracy: 0.3750 - val_loss: 0.2497 - val_accuracy: 1.0000\n",
            "Epoch 4/200\n",
            "319/319 [==============================] - 33s 105ms/step - loss: 0.8679 - accuracy: 0.3750 - val_loss: 0.2611 - val_accuracy: 1.0000\n",
            "Epoch 5/200\n",
            "319/319 [==============================] - 34s 108ms/step - loss: 0.8618 - accuracy: 0.3750 - val_loss: 0.1930 - val_accuracy: 1.0000\n",
            "Epoch 6/200\n",
            "319/319 [==============================] - 33s 102ms/step - loss: 0.8547 - accuracy: 0.3750 - val_loss: 0.2198 - val_accuracy: 1.0000\n",
            "Epoch 7/200\n",
            "319/319 [==============================] - 39s 122ms/step - loss: 0.8465 - accuracy: 0.3750 - val_loss: 0.2081 - val_accuracy: 1.0000\n",
            "Epoch 8/200\n",
            "319/319 [==============================] - 37s 115ms/step - loss: 0.8352 - accuracy: 0.3750 - val_loss: 0.2425 - val_accuracy: 1.0000\n",
            "Epoch 9/200\n",
            "319/319 [==============================] - 42s 131ms/step - loss: 0.8237 - accuracy: 0.3750 - val_loss: 0.2140 - val_accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "319/319 [==============================] - 43s 135ms/step - loss: 0.8092 - accuracy: 0.3750 - val_loss: 0.1972 - val_accuracy: 1.0000\n",
            "Epoch 11/200\n",
            "319/319 [==============================] - 52s 162ms/step - loss: 0.7932 - accuracy: 0.4810 - val_loss: 0.1816 - val_accuracy: 0.9578\n",
            "Epoch 12/200\n",
            "319/319 [==============================] - 53s 166ms/step - loss: 0.7707 - accuracy: 0.5402 - val_loss: 0.1855 - val_accuracy: 0.9608\n",
            "Epoch 13/200\n",
            "319/319 [==============================] - 57s 178ms/step - loss: 0.7466 - accuracy: 0.5720 - val_loss: 0.1930 - val_accuracy: 0.9390\n",
            "Epoch 14/200\n",
            "319/319 [==============================] - 60s 187ms/step - loss: 0.7200 - accuracy: 0.5972 - val_loss: 0.2007 - val_accuracy: 0.9382\n",
            "Epoch 15/200\n",
            "319/319 [==============================] - 57s 179ms/step - loss: 0.6884 - accuracy: 0.6269 - val_loss: 0.1894 - val_accuracy: 0.9295\n",
            "Epoch 16/200\n",
            "319/319 [==============================] - 56s 175ms/step - loss: 0.6628 - accuracy: 0.6493 - val_loss: 0.1743 - val_accuracy: 0.9467\n",
            "Epoch 17/200\n",
            "319/319 [==============================] - 53s 166ms/step - loss: 0.6340 - accuracy: 0.6732 - val_loss: 0.1982 - val_accuracy: 0.9231\n",
            "Epoch 18/200\n",
            "319/319 [==============================] - 52s 164ms/step - loss: 0.6067 - accuracy: 0.6957 - val_loss: 0.1696 - val_accuracy: 0.9415\n",
            "Epoch 19/200\n",
            "319/319 [==============================] - 54s 171ms/step - loss: 0.5778 - accuracy: 0.7145 - val_loss: 0.2007 - val_accuracy: 0.9307\n",
            "Epoch 20/200\n",
            "319/319 [==============================] - 58s 181ms/step - loss: 0.5505 - accuracy: 0.7323 - val_loss: 0.1415 - val_accuracy: 0.9626\n",
            "Epoch 21/200\n",
            "319/319 [==============================] - 63s 199ms/step - loss: 0.5171 - accuracy: 0.7552 - val_loss: 0.1713 - val_accuracy: 0.9478\n",
            "Epoch 22/200\n",
            "319/319 [==============================] - 59s 186ms/step - loss: 0.5034 - accuracy: 0.7658 - val_loss: 0.1265 - val_accuracy: 0.9631\n",
            "Epoch 23/200\n",
            "319/319 [==============================] - 58s 183ms/step - loss: 0.4795 - accuracy: 0.7793 - val_loss: 0.1411 - val_accuracy: 0.9507\n",
            "Epoch 24/200\n",
            "319/319 [==============================] - 57s 179ms/step - loss: 0.4612 - accuracy: 0.7895 - val_loss: 0.1555 - val_accuracy: 0.9540\n",
            "Epoch 25/200\n",
            "319/319 [==============================] - 63s 198ms/step - loss: 0.4365 - accuracy: 0.8035 - val_loss: 0.1433 - val_accuracy: 0.9577\n",
            "Epoch 26/200\n",
            "319/319 [==============================] - 60s 188ms/step - loss: 0.4143 - accuracy: 0.8186 - val_loss: 0.1367 - val_accuracy: 0.9552\n",
            "Epoch 27/200\n",
            "319/319 [==============================] - 58s 182ms/step - loss: 0.4011 - accuracy: 0.8245 - val_loss: 0.1377 - val_accuracy: 0.9561\n",
            "Epoch 28/200\n",
            "319/319 [==============================] - 52s 162ms/step - loss: 0.3838 - accuracy: 0.8339 - val_loss: 0.1205 - val_accuracy: 0.9688\n",
            "Epoch 29/200\n",
            "319/319 [==============================] - 56s 176ms/step - loss: 0.3716 - accuracy: 0.8410 - val_loss: 0.1185 - val_accuracy: 0.9637\n",
            "Epoch 30/200\n",
            "319/319 [==============================] - 60s 188ms/step - loss: 0.3559 - accuracy: 0.8512 - val_loss: 0.1377 - val_accuracy: 0.9531\n",
            "Epoch 31/200\n",
            "319/319 [==============================] - 60s 189ms/step - loss: 0.3372 - accuracy: 0.8612 - val_loss: 0.1123 - val_accuracy: 0.9668\n",
            "Epoch 32/200\n",
            "319/319 [==============================] - 60s 188ms/step - loss: 0.3298 - accuracy: 0.8640 - val_loss: 0.1039 - val_accuracy: 0.9702\n",
            "Epoch 33/200\n",
            "319/319 [==============================] - 62s 194ms/step - loss: 0.3201 - accuracy: 0.8687 - val_loss: 0.1231 - val_accuracy: 0.9667\n",
            "Epoch 34/200\n",
            "319/319 [==============================] - 64s 200ms/step - loss: 0.3103 - accuracy: 0.8764 - val_loss: 0.0991 - val_accuracy: 0.9690\n",
            "Epoch 35/200\n",
            "319/319 [==============================] - 58s 181ms/step - loss: 0.2942 - accuracy: 0.8857 - val_loss: 0.0961 - val_accuracy: 0.9737\n",
            "Epoch 36/200\n",
            "319/319 [==============================] - 58s 182ms/step - loss: 0.2927 - accuracy: 0.8872 - val_loss: 0.0906 - val_accuracy: 0.9726\n",
            "Epoch 37/200\n",
            "319/319 [==============================] - 62s 195ms/step - loss: 0.2781 - accuracy: 0.8937 - val_loss: 0.0976 - val_accuracy: 0.9729\n",
            "Epoch 38/200\n",
            "319/319 [==============================] - 60s 188ms/step - loss: 0.2767 - accuracy: 0.8966 - val_loss: 0.0916 - val_accuracy: 0.9760\n",
            "Epoch 39/200\n",
            "319/319 [==============================] - 60s 188ms/step - loss: 0.2699 - accuracy: 0.8990 - val_loss: 0.1032 - val_accuracy: 0.9679\n",
            "Epoch 40/200\n",
            "319/319 [==============================] - 57s 178ms/step - loss: 0.2574 - accuracy: 0.9052 - val_loss: 0.1045 - val_accuracy: 0.9675\n",
            "Epoch 41/200\n",
            "319/319 [==============================] - 63s 198ms/step - loss: 0.2486 - accuracy: 0.9102 - val_loss: 0.0957 - val_accuracy: 0.9724\n",
            "Epoch 42/200\n",
            "319/319 [==============================] - 60s 188ms/step - loss: 0.2462 - accuracy: 0.9112 - val_loss: 0.0944 - val_accuracy: 0.9706\n",
            "Epoch 43/200\n",
            "319/319 [==============================] - 58s 181ms/step - loss: 0.2385 - accuracy: 0.9150 - val_loss: 0.0904 - val_accuracy: 0.9755\n",
            "Epoch 44/200\n",
            "319/319 [==============================] - 53s 165ms/step - loss: 0.2360 - accuracy: 0.9160 - val_loss: 0.0884 - val_accuracy: 0.9782\n",
            "Epoch 45/200\n",
            "319/319 [==============================] - 64s 200ms/step - loss: 0.2288 - accuracy: 0.9186 - val_loss: 0.0918 - val_accuracy: 0.9773\n",
            "Epoch 46/200\n",
            "319/319 [==============================] - 60s 188ms/step - loss: 0.2199 - accuracy: 0.9231 - val_loss: 0.0871 - val_accuracy: 0.9788\n",
            "Epoch 47/200\n",
            "319/319 [==============================] - 62s 194ms/step - loss: 0.2240 - accuracy: 0.9214 - val_loss: 0.0877 - val_accuracy: 0.9782\n",
            "Epoch 48/200\n",
            "319/319 [==============================] - 61s 190ms/step - loss: 0.2152 - accuracy: 0.9269 - val_loss: 0.1000 - val_accuracy: 0.9717\n",
            "Epoch 49/200\n",
            "319/319 [==============================] - 60s 189ms/step - loss: 0.2128 - accuracy: 0.9276 - val_loss: 0.0868 - val_accuracy: 0.9777\n",
            "Epoch 50/200\n",
            "319/319 [==============================] - 55s 173ms/step - loss: 0.2079 - accuracy: 0.9291 - val_loss: 0.0864 - val_accuracy: 0.9777\n",
            "Epoch 51/200\n",
            "319/319 [==============================] - 53s 167ms/step - loss: 0.1984 - accuracy: 0.9346 - val_loss: 0.0871 - val_accuracy: 0.9736\n",
            "Epoch 52/200\n",
            "319/319 [==============================] - 62s 194ms/step - loss: 0.2059 - accuracy: 0.9321 - val_loss: 0.0760 - val_accuracy: 0.9819\n",
            "Epoch 53/200\n",
            "319/319 [==============================] - 58s 181ms/step - loss: 0.1849 - accuracy: 0.9410 - val_loss: 0.0827 - val_accuracy: 0.9784\n",
            "Epoch 54/200\n",
            "319/319 [==============================] - 53s 167ms/step - loss: 0.1915 - accuracy: 0.9357 - val_loss: 0.0648 - val_accuracy: 0.9821\n",
            "Epoch 55/200\n",
            "319/319 [==============================] - 54s 169ms/step - loss: 0.1864 - accuracy: 0.9385 - val_loss: 0.0748 - val_accuracy: 0.9802\n",
            "Epoch 56/200\n",
            "319/319 [==============================] - 58s 180ms/step - loss: 0.1906 - accuracy: 0.9377 - val_loss: 0.0881 - val_accuracy: 0.9737\n",
            "Epoch 57/200\n",
            "319/319 [==============================] - 63s 196ms/step - loss: 0.1756 - accuracy: 0.9453 - val_loss: 0.0892 - val_accuracy: 0.9806\n",
            "Epoch 58/200\n",
            "319/319 [==============================] - 57s 178ms/step - loss: 0.1786 - accuracy: 0.9431 - val_loss: 0.0746 - val_accuracy: 0.9788\n",
            "Epoch 59/200\n",
            "319/319 [==============================] - 52s 162ms/step - loss: 0.1744 - accuracy: 0.9458 - val_loss: 0.0855 - val_accuracy: 0.9781\n",
            "Epoch 60/200\n",
            "319/319 [==============================] - 57s 180ms/step - loss: 0.1742 - accuracy: 0.9458 - val_loss: 0.0643 - val_accuracy: 0.9820\n",
            "Epoch 61/200\n",
            "319/319 [==============================] - 62s 194ms/step - loss: 0.1654 - accuracy: 0.9494 - val_loss: 0.0764 - val_accuracy: 0.9818\n",
            "Epoch 62/200\n",
            "319/319 [==============================] - 63s 196ms/step - loss: 0.1671 - accuracy: 0.9483 - val_loss: 0.0655 - val_accuracy: 0.9830\n",
            "Epoch 63/200\n",
            "319/319 [==============================] - 58s 183ms/step - loss: 0.1666 - accuracy: 0.9481 - val_loss: 0.0700 - val_accuracy: 0.9834\n",
            "Epoch 64/200\n",
            "319/319 [==============================] - 53s 168ms/step - loss: 0.1696 - accuracy: 0.9470 - val_loss: 0.0748 - val_accuracy: 0.9819\n",
            "Epoch 65/200\n",
            "319/319 [==============================] - 52s 163ms/step - loss: 0.1579 - accuracy: 0.9522 - val_loss: 0.0596 - val_accuracy: 0.9853\n",
            "Epoch 66/200\n",
            "319/319 [==============================] - 56s 176ms/step - loss: 0.1663 - accuracy: 0.9481 - val_loss: 0.0724 - val_accuracy: 0.9803\n",
            "Epoch 67/200\n",
            "319/319 [==============================] - 56s 175ms/step - loss: 0.1544 - accuracy: 0.9538 - val_loss: 0.0809 - val_accuracy: 0.9780\n",
            "Epoch 68/200\n",
            "319/319 [==============================] - 56s 176ms/step - loss: 0.1564 - accuracy: 0.9521 - val_loss: 0.0653 - val_accuracy: 0.9856\n",
            "Epoch 69/200\n",
            "319/319 [==============================] - 53s 166ms/step - loss: 0.1536 - accuracy: 0.9535 - val_loss: 0.0590 - val_accuracy: 0.9848\n",
            "Epoch 70/200\n",
            "319/319 [==============================] - 55s 172ms/step - loss: 0.1483 - accuracy: 0.9562 - val_loss: 0.0565 - val_accuracy: 0.9858\n",
            "Epoch 71/200\n",
            "319/319 [==============================] - 58s 182ms/step - loss: 0.1591 - accuracy: 0.9519 - val_loss: 0.0602 - val_accuracy: 0.9856\n",
            "Epoch 72/200\n",
            "319/319 [==============================] - 63s 196ms/step - loss: 0.1503 - accuracy: 0.9566 - val_loss: 0.0551 - val_accuracy: 0.9871\n",
            "Epoch 73/200\n",
            "319/319 [==============================] - 54s 170ms/step - loss: 0.1595 - accuracy: 0.9547 - val_loss: 0.0585 - val_accuracy: 0.9868\n",
            "Epoch 74/200\n",
            "319/319 [==============================] - 55s 172ms/step - loss: 0.1387 - accuracy: 0.9584 - val_loss: 0.0588 - val_accuracy: 0.9889\n",
            "Epoch 75/200\n",
            "319/319 [==============================] - 58s 181ms/step - loss: 0.1467 - accuracy: 0.9525 - val_loss: 0.0509 - val_accuracy: 0.9915\n",
            "Epoch 76/200\n",
            "319/319 [==============================] - 57s 180ms/step - loss: 0.1350 - accuracy: 0.9569 - val_loss: 0.0611 - val_accuracy: 0.9828\n",
            "Epoch 77/200\n",
            "319/319 [==============================] - 53s 166ms/step - loss: 0.1208 - accuracy: 0.9591 - val_loss: 0.0298 - val_accuracy: 0.9955\n",
            "Epoch 78/200\n",
            "319/319 [==============================] - 57s 180ms/step - loss: 0.1171 - accuracy: 0.9616 - val_loss: 0.0303 - val_accuracy: 0.9949\n",
            "Epoch 79/200\n",
            "319/319 [==============================] - 57s 179ms/step - loss: 0.1232 - accuracy: 0.9577 - val_loss: 0.0249 - val_accuracy: 0.9960\n",
            "Epoch 80/200\n",
            "319/319 [==============================] - 57s 178ms/step - loss: 0.1128 - accuracy: 0.9624 - val_loss: 0.0314 - val_accuracy: 0.9958\n",
            "Epoch 81/200\n",
            "319/319 [==============================] - 58s 181ms/step - loss: 0.1032 - accuracy: 0.9672 - val_loss: 0.0340 - val_accuracy: 0.9941\n",
            "Epoch 82/200\n",
            "319/319 [==============================] - 57s 178ms/step - loss: 0.1132 - accuracy: 0.9622 - val_loss: 0.0602 - val_accuracy: 0.9863\n",
            "Epoch 83/200\n",
            "319/319 [==============================] - 51s 161ms/step - loss: 0.1077 - accuracy: 0.9635 - val_loss: 0.0305 - val_accuracy: 0.9952\n",
            "Epoch 84/200\n",
            "319/319 [==============================] - 52s 162ms/step - loss: 0.1030 - accuracy: 0.9655 - val_loss: 0.0480 - val_accuracy: 0.9936\n",
            "Epoch 85/200\n",
            "319/319 [==============================] - 56s 174ms/step - loss: 0.1311 - accuracy: 0.9580 - val_loss: 0.0319 - val_accuracy: 0.9949\n",
            "Epoch 86/200\n",
            "319/319 [==============================] - 58s 181ms/step - loss: 0.0948 - accuracy: 0.9685 - val_loss: 0.0371 - val_accuracy: 0.9947\n",
            "Epoch 87/200\n",
            "319/319 [==============================] - 57s 177ms/step - loss: 0.1012 - accuracy: 0.9666 - val_loss: 0.0252 - val_accuracy: 0.9962\n",
            "Epoch 88/200\n",
            "319/319 [==============================] - 58s 183ms/step - loss: 0.1027 - accuracy: 0.9656 - val_loss: 0.0282 - val_accuracy: 0.9955\n",
            "Epoch 89/200\n",
            "319/319 [==============================] - 55s 173ms/step - loss: 0.0977 - accuracy: 0.9677 - val_loss: 0.0392 - val_accuracy: 0.9945\n",
            "Epoch 90/200\n",
            "319/319 [==============================] - 48s 150ms/step - loss: 0.1015 - accuracy: 0.9655 - val_loss: 0.0238 - val_accuracy: 0.9963\n",
            "Epoch 91/200\n",
            "319/319 [==============================] - 62s 195ms/step - loss: 0.1012 - accuracy: 0.9672 - val_loss: 0.0993 - val_accuracy: 0.9774\n",
            "Epoch 92/200\n",
            "319/319 [==============================] - 57s 178ms/step - loss: 0.1249 - accuracy: 0.9620 - val_loss: 0.0317 - val_accuracy: 0.9942\n",
            "Epoch 93/200\n",
            "319/319 [==============================] - 58s 181ms/step - loss: 0.1005 - accuracy: 0.9691 - val_loss: 0.0458 - val_accuracy: 0.9939\n",
            "Epoch 94/200\n",
            "319/319 [==============================] - 58s 181ms/step - loss: 0.1057 - accuracy: 0.9665 - val_loss: 0.0318 - val_accuracy: 0.9940\n",
            "Epoch 95/200\n",
            "319/319 [==============================] - 57s 179ms/step - loss: 0.0822 - accuracy: 0.9733 - val_loss: 0.0363 - val_accuracy: 0.9929\n",
            "Epoch 96/200\n",
            "319/319 [==============================] - 57s 179ms/step - loss: 0.0905 - accuracy: 0.9691 - val_loss: 0.0468 - val_accuracy: 0.9897\n",
            "Epoch 97/200\n",
            "319/319 [==============================] - 62s 196ms/step - loss: 0.0847 - accuracy: 0.9713 - val_loss: 0.0253 - val_accuracy: 0.9962\n",
            "Epoch 98/200\n",
            "319/319 [==============================] - 61s 192ms/step - loss: 0.0857 - accuracy: 0.9713 - val_loss: 0.0225 - val_accuracy: 0.9959\n",
            "Epoch 99/200\n",
            "319/319 [==============================] - 60s 188ms/step - loss: 0.0848 - accuracy: 0.9716 - val_loss: 0.0553 - val_accuracy: 0.9855\n",
            "Epoch 100/200\n",
            "319/319 [==============================] - 61s 193ms/step - loss: 0.0887 - accuracy: 0.9703 - val_loss: 0.0297 - val_accuracy: 0.9949\n",
            "Epoch 101/200\n",
            "319/319 [==============================] - 58s 183ms/step - loss: 0.0804 - accuracy: 0.9739 - val_loss: 0.0543 - val_accuracy: 0.9961\n",
            "Epoch 102/200\n",
            "319/319 [==============================] - 61s 191ms/step - loss: 0.1225 - accuracy: 0.9650 - val_loss: 0.0513 - val_accuracy: 0.9876\n",
            "Epoch 103/200\n",
            "319/319 [==============================] - 56s 177ms/step - loss: 0.1005 - accuracy: 0.9686 - val_loss: 0.0253 - val_accuracy: 0.9955\n",
            "Epoch 104/200\n",
            "319/319 [==============================] - 58s 182ms/step - loss: 0.0777 - accuracy: 0.9748 - val_loss: 0.0219 - val_accuracy: 0.9964\n",
            "Epoch 105/200\n",
            "319/319 [==============================] - 58s 183ms/step - loss: 0.0792 - accuracy: 0.9727 - val_loss: 0.0274 - val_accuracy: 0.9945\n",
            "Epoch 106/200\n",
            "319/319 [==============================] - 55s 172ms/step - loss: 0.1053 - accuracy: 0.9673 - val_loss: 0.0264 - val_accuracy: 0.9963\n",
            "Epoch 107/200\n",
            "319/319 [==============================] - 60s 188ms/step - loss: 0.0843 - accuracy: 0.9734 - val_loss: 0.0382 - val_accuracy: 0.9917\n",
            "Epoch 108/200\n",
            "319/319 [==============================] - 63s 196ms/step - loss: 0.0759 - accuracy: 0.9750 - val_loss: 0.0213 - val_accuracy: 0.9953\n",
            "Epoch 109/200\n",
            "319/319 [==============================] - 57s 179ms/step - loss: 0.0712 - accuracy: 0.9766 - val_loss: 0.0168 - val_accuracy: 0.9965\n",
            "Epoch 110/200\n",
            "319/319 [==============================] - 60s 189ms/step - loss: 0.0758 - accuracy: 0.9745 - val_loss: 0.0223 - val_accuracy: 0.9966\n",
            "Epoch 111/200\n",
            "319/319 [==============================] - 60s 188ms/step - loss: 0.0795 - accuracy: 0.9735 - val_loss: 0.0184 - val_accuracy: 0.9977\n",
            "Epoch 112/200\n",
            "319/319 [==============================] - 56s 175ms/step - loss: 0.0770 - accuracy: 0.9745 - val_loss: 0.0241 - val_accuracy: 0.9939\n",
            "Epoch 113/200\n",
            "319/319 [==============================] - 54s 170ms/step - loss: 0.0754 - accuracy: 0.9743 - val_loss: 0.0218 - val_accuracy: 0.9970\n",
            "Epoch 114/200\n",
            "319/319 [==============================] - 58s 182ms/step - loss: 0.0742 - accuracy: 0.9747 - val_loss: 0.0182 - val_accuracy: 0.9977\n",
            "Epoch 115/200\n",
            "319/319 [==============================] - 62s 193ms/step - loss: 0.0740 - accuracy: 0.9746 - val_loss: 0.0229 - val_accuracy: 0.9963\n",
            "Epoch 116/200\n",
            "319/319 [==============================] - 58s 181ms/step - loss: 0.0721 - accuracy: 0.9764 - val_loss: 0.0540 - val_accuracy: 0.9963\n",
            "Epoch 117/200\n",
            "319/319 [==============================] - 58s 183ms/step - loss: 0.0798 - accuracy: 0.9746 - val_loss: 0.0177 - val_accuracy: 0.9976\n",
            "Epoch 118/200\n",
            "319/319 [==============================] - 56s 176ms/step - loss: 0.0760 - accuracy: 0.9767 - val_loss: 0.0211 - val_accuracy: 0.9955\n",
            "Epoch 119/200\n",
            "319/319 [==============================] - 52s 163ms/step - loss: 0.0684 - accuracy: 0.9771 - val_loss: 0.0462 - val_accuracy: 0.9882\n",
            "Epoch 120/200\n",
            "319/319 [==============================] - 56s 176ms/step - loss: 0.0865 - accuracy: 0.9736 - val_loss: 0.0206 - val_accuracy: 0.9981\n",
            "Epoch 121/200\n",
            "319/319 [==============================] - 61s 192ms/step - loss: 0.0596 - accuracy: 0.9811 - val_loss: 0.0157 - val_accuracy: 0.9984\n",
            "Epoch 122/200\n",
            "319/319 [==============================] - 59s 185ms/step - loss: 0.0725 - accuracy: 0.9759 - val_loss: 0.0273 - val_accuracy: 0.9959\n",
            "Epoch 123/200\n",
            "319/319 [==============================] - 60s 188ms/step - loss: 0.0728 - accuracy: 0.9772 - val_loss: 0.0363 - val_accuracy: 0.9935\n",
            "Epoch 124/200\n",
            "319/319 [==============================] - 51s 160ms/step - loss: 0.0794 - accuracy: 0.9755 - val_loss: 0.0261 - val_accuracy: 0.9963\n",
            "Epoch 125/200\n",
            "319/319 [==============================] - 61s 191ms/step - loss: 0.0716 - accuracy: 0.9775 - val_loss: 0.0362 - val_accuracy: 0.9914\n",
            "Epoch 126/200\n",
            "319/319 [==============================] - 60s 187ms/step - loss: 0.0701 - accuracy: 0.9784 - val_loss: 0.0148 - val_accuracy: 0.9981\n",
            "Epoch 127/200\n",
            "319/319 [==============================] - 54s 169ms/step - loss: 0.0699 - accuracy: 0.9788 - val_loss: 0.0255 - val_accuracy: 0.9969\n",
            "Epoch 128/200\n",
            "319/319 [==============================] - 57s 180ms/step - loss: 0.0793 - accuracy: 0.9751 - val_loss: 0.0181 - val_accuracy: 0.9975\n",
            "Epoch 129/200\n",
            "319/319 [==============================] - 59s 185ms/step - loss: 0.0691 - accuracy: 0.9763 - val_loss: 0.0236 - val_accuracy: 0.9941\n",
            "Epoch 130/200\n",
            "319/319 [==============================] - 57s 180ms/step - loss: 0.0647 - accuracy: 0.9789 - val_loss: 0.0265 - val_accuracy: 0.9945\n",
            "Epoch 131/200\n",
            "319/319 [==============================] - 58s 183ms/step - loss: 0.0622 - accuracy: 0.9794 - val_loss: 0.0221 - val_accuracy: 0.9960\n",
            "Epoch 132/200\n",
            "319/319 [==============================] - 65s 203ms/step - loss: 0.0699 - accuracy: 0.9778 - val_loss: 0.0148 - val_accuracy: 0.9988\n",
            "Epoch 133/200\n",
            "319/319 [==============================] - 60s 187ms/step - loss: 0.0611 - accuracy: 0.9814 - val_loss: 0.0192 - val_accuracy: 0.9975\n",
            "Epoch 134/200\n",
            "319/319 [==============================] - 61s 191ms/step - loss: 0.0648 - accuracy: 0.9796 - val_loss: 0.0438 - val_accuracy: 0.9885\n",
            "Epoch 135/200\n",
            "319/319 [==============================] - 59s 185ms/step - loss: 0.0643 - accuracy: 0.9796 - val_loss: 0.0207 - val_accuracy: 0.9965\n",
            "Epoch 136/200\n",
            "319/319 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.9797"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(\"xu030-long-deneme.h5\")\n",
        "# model = tf.keras.models.load_model(\"best_model.h5\")\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "jqRgrzZg084k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for stock in [\"TUPRS.IS\"]:\n",
        "  predictions = []\n",
        "\n",
        "  stock_data = yf.download(stock, start=\"2000-01-01\", end=\"2023-08-10\", progress=False)\n",
        "  stock_data = create_indicators(stock_data)\n",
        "\n",
        "  stock_data[\"signal\"] = 0\n",
        "\n",
        "  for row in range(stock_data.shape[0]):\n",
        "    if row+1 != stock_data.shape[0] and stock_data[\"Close\"].iloc[row+1] > stock_data[\"Close\"].iloc[row] + 5*(stock_data[\"Close\"].iloc[row])/100:\n",
        "      stock_data[\"signal\"].iloc[row] = 1\n",
        "\n",
        "  stock_data = stock_data.drop([\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"], axis=1)\n",
        "\n",
        "  for index, row in stock_data.iterrows():\n",
        "      x = row[1:34]\n",
        "\n",
        "      new_data = x.to_numpy().reshape(1, -1)\n",
        "      new_data = scaler.transform(new_data)\n",
        "      prediction = model.predict(new_data, verbose=None)\n",
        "\n",
        "      # print(f\"Prediction for date {row[0]}: {np.round(prediction[0][0])}\")\n",
        "\n",
        "      if np.round(prediction[0][0]) == row[\"signal\"]:\n",
        "        predictions.append(1)\n",
        "      elif np.round(prediction[0][0]) != row[\"signal\"]:\n",
        "        predictions.append(0)\n",
        "\n",
        "  print(f\"{stock} Accuracy: {predictions.count(1) / len(predictions) * 100}\")"
      ],
      "metadata": {
        "id": "GXskMvribBZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buy_stocks = []\n",
        "\n",
        "for stock in result_df[\"STOCK\"].unique():\n",
        "  stock_data = yf.download(stock, start=\"2021-06-01\", end=\"2023-08-16\", progress=False)\n",
        "  stock_data = create_indicators(stock_data)\n",
        "\n",
        "  change = ((stock_data[\"Close\"].iloc[-1] - stock_data[\"Close\"].iloc[-2]) / stock_data[\"Close\"].iloc[-2])*100\n",
        "  change = round(change, 2)\n",
        "\n",
        "  stock_data = stock_data.drop([\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"], axis=1)\n",
        "\n",
        "  x = stock_data.iloc[-2]\n",
        "\n",
        "  new_data = x.to_numpy().reshape(1, -1)\n",
        "  new_data = scaler.transform(new_data)\n",
        "  prediction = model.predict(new_data, verbose=None)\n",
        "\n",
        "  if round(prediction[0][0]*100,2) > 75:\n",
        "    buy_stocks.append([stock, round(prediction[0][0]*100,2), change])\n",
        "\n",
        "buy_df = pd.DataFrame(buy_stocks, columns=[\"stock\", \"probability\", \"change\"]).sort_values(by=\"probability\", ascending=False)\n",
        "print(f'Pozitif kapanan hisse sayısı: {buy_df[buy_df[\"change\"] > 0].shape[0]}')\n",
        "print(f'Negatif kapanan hisse sayısı: {buy_df[buy_df[\"change\"] < 0].shape[0]}')\n",
        "print(f'Günlük değişim ortalaması: %{round(buy_df[\"change\"].sum()/buy_df.shape[0], 2)}\\n')\n",
        "buy_df"
      ],
      "metadata": {
        "id": "YASh8fggUiZk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "ccb9a14c-cb7d-4880-e76c-3318772e1702"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pozitif kapanan hisse sayısı: 9\n",
            "Negatif kapanan hisse sayısı: 14\n",
            "Günlük değişim ortalaması: %-0.53\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       stock  probability  change\n",
              "5    ALKA.IS        99.95   -1.79\n",
              "1   TAVHL.IS        99.70    1.33\n",
              "3   ADESE.IS        99.59   -9.76\n",
              "15  GLCVY.IS        99.01    0.00\n",
              "2    ADEL.IS        97.87    9.99\n",
              "8   BRSAN.IS        97.72   -2.29\n",
              "6   ANGEN.IS        97.22   -2.04\n",
              "16  NETAS.IS        96.71   -4.69\n",
              "18  POLTK.IS        96.11    0.00\n",
              "11   ERSU.IS        95.81   -8.20\n",
              "22  TTRAK.IS        95.45    3.22\n",
              "21  SKBNK.IS        94.97   -1.98\n",
              "0   EREGL.IS        94.44   -2.35\n",
              "4   AKSUE.IS        93.62    1.56\n",
              "17  PNSUT.IS        93.46   -1.87\n",
              "23  VKFYO.IS        92.76   -6.32\n",
              "13  ETYAT.IS        92.61    2.72\n",
              "19  QNBFL.IS        91.95   -4.49\n",
              "9   BFREN.IS        91.24   -0.92\n",
              "10  DERIM.IS        90.94   -2.03\n",
              "7   ATATP.IS        87.94   -1.80\n",
              "24  YONGA.IS        87.56    0.33\n",
              "12  EUKYO.IS        84.05    6.03\n",
              "14  GSRAY.IS        77.99    2.25\n",
              "20  SAFKR.IS        75.15    9.93"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c7d79c7-0a7f-47f5-8cf2-31d8f7015edd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock</th>\n",
              "      <th>probability</th>\n",
              "      <th>change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ALKA.IS</td>\n",
              "      <td>99.95</td>\n",
              "      <td>-1.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TAVHL.IS</td>\n",
              "      <td>99.70</td>\n",
              "      <td>1.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ADESE.IS</td>\n",
              "      <td>99.59</td>\n",
              "      <td>-9.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>GLCVY.IS</td>\n",
              "      <td>99.01</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADEL.IS</td>\n",
              "      <td>97.87</td>\n",
              "      <td>9.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>BRSAN.IS</td>\n",
              "      <td>97.72</td>\n",
              "      <td>-2.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ANGEN.IS</td>\n",
              "      <td>97.22</td>\n",
              "      <td>-2.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NETAS.IS</td>\n",
              "      <td>96.71</td>\n",
              "      <td>-4.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>POLTK.IS</td>\n",
              "      <td>96.11</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ERSU.IS</td>\n",
              "      <td>95.81</td>\n",
              "      <td>-8.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>TTRAK.IS</td>\n",
              "      <td>95.45</td>\n",
              "      <td>3.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>SKBNK.IS</td>\n",
              "      <td>94.97</td>\n",
              "      <td>-1.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EREGL.IS</td>\n",
              "      <td>94.44</td>\n",
              "      <td>-2.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AKSUE.IS</td>\n",
              "      <td>93.62</td>\n",
              "      <td>1.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>PNSUT.IS</td>\n",
              "      <td>93.46</td>\n",
              "      <td>-1.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>VKFYO.IS</td>\n",
              "      <td>92.76</td>\n",
              "      <td>-6.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ETYAT.IS</td>\n",
              "      <td>92.61</td>\n",
              "      <td>2.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>QNBFL.IS</td>\n",
              "      <td>91.95</td>\n",
              "      <td>-4.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>BFREN.IS</td>\n",
              "      <td>91.24</td>\n",
              "      <td>-0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>DERIM.IS</td>\n",
              "      <td>90.94</td>\n",
              "      <td>-2.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ATATP.IS</td>\n",
              "      <td>87.94</td>\n",
              "      <td>-1.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>YONGA.IS</td>\n",
              "      <td>87.56</td>\n",
              "      <td>0.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>EUKYO.IS</td>\n",
              "      <td>84.05</td>\n",
              "      <td>6.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>GSRAY.IS</td>\n",
              "      <td>77.99</td>\n",
              "      <td>2.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>SAFKR.IS</td>\n",
              "      <td>75.15</td>\n",
              "      <td>9.93</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c7d79c7-0a7f-47f5-8cf2-31d8f7015edd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c7d79c7-0a7f-47f5-8cf2-31d8f7015edd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c7d79c7-0a7f-47f5-8cf2-31d8f7015edd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b54d6a82-2d13-4ef0-befa-277d4ddaffd6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b54d6a82-2d13-4ef0-befa-277d4ddaffd6')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b54d6a82-2d13-4ef0-befa-277d4ddaffd6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Ccc0G_6rn1w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
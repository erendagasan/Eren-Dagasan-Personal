{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erendagasan/Eren-Dagasan-Personal/blob/main/gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Libraries and Indicator Function\n",
        "\n",
        "!pip install -q bta-lib\n",
        "!pip install -q ta\n",
        "\n",
        "import btalib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ta.trend import PSARIndicator\n",
        "from ta.momentum import WilliamsRIndicator\n",
        "from ta.trend import AroonIndicator\n",
        "from ta.volume import VolumePriceTrendIndicator\n",
        "from ta.trend import CCIIndicator\n",
        "from ta.momentum import ROCIndicator\n",
        "from ta.trend import ADXIndicator\n",
        "from ta.momentum import ultimate_oscillator\n",
        "from ta.volume import ChaikinMoneyFlowIndicator\n",
        "from ta.trend import KSTIndicator\n",
        "from ta.momentum import TSIIndicator\n",
        "from ta.trend import WMAIndicator\n",
        "import yfinance as yf\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "def create_indicators(data):\n",
        "  data[\"RSI-14\"] = btalib.rsi(data[\"Close\"], period=14).df\n",
        "  data[\"RSI-60\"] = btalib.rsi(data[\"Close\"], period=60).df\n",
        "\n",
        "  data[\"STOCH-K\"] = btalib.stoch(data['High'], data['Low'], data['Close']).df[\"k\"]\n",
        "  data[\"STOCH-D\"] = btalib.stoch(data['High'], data['Low'], data['Close']).df[\"d\"]\n",
        "\n",
        "  data[\"WILLIAMS\"] = WilliamsRIndicator(data[\"High\"], data[\"Low\"], data[\"Close\"]).williams_r()\n",
        "  data[\"AROON\"] = AroonIndicator(close=data[\"Close\"], window=25).aroon_indicator()\n",
        "  data['CCI'] = CCIIndicator(close=data['Close'], low=data[\"Low\"], high=data[\"High\"], window=14).cci()\n",
        "  data['ROC'] = ROCIndicator(close=data['Close'], window=5).roc()\n",
        "\n",
        "  adx_indicator = ADXIndicator(high=data['High'], low=data['Low'], close=data['Close'], window=14)\n",
        "  data['ADX'] = adx_indicator.adx()\n",
        "  data['+DI'] = adx_indicator.adx_pos()\n",
        "  data['-DI'] = adx_indicator.adx_neg()\n",
        "\n",
        "  data['ULTIMATE-OSC'] = ultimate_oscillator(high=data['High'], low=data['Low'], close=data['Close'], window1=7, window2=14, window3=28)\n",
        "  data['MONEY-FLOW'] = ChaikinMoneyFlowIndicator(high=data['High'], low=data['Low'], close=data['Close'], volume=data['Volume'], window=20).chaikin_money_flow()\n",
        "  data['KST'] = KSTIndicator(data['Close']).kst()\n",
        "\n",
        "  data['TSI'] = TSIIndicator(data['Close']).tsi()\n",
        "\n",
        "  data['WMA-30'] = WMAIndicator(data['Close'], window=30).wma()\n",
        "\n",
        "  data = data.dropna()\n",
        "  data = data.reset_index()\n",
        "  return data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Lfv1WZ9SIIPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0695e1a1-bc97-4389-9ecc-6f482006423d",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/92.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the Model\n",
        "\n",
        "import gdown\n",
        "\n",
        "gdown.download(\"https://drive.google.com/u/1/uc?id=1-3r7tu0ZQXWNtqMQ35rX0DexxNt9P1l5&export=download\", \"/content/\", quiet=False)\n",
        "# gdown.download(\"https://drive.google.com/u/0/uc?id=117pezAA6jRLCwIsdpEhZgEa9tEanlC0O&export=download\", \"/content/\", quiet=False)\n",
        "\n",
        "# data = pd.read_csv(\"data.csv\")\n",
        "model = tf.keras.models.load_model(\"best_model_2.h5\")"
      ],
      "metadata": {
        "id": "j0_ac_MyLUax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Stock List\n",
        "sheet_id = \"1RSqOXkFTAO7g4H9LEY3d3IX6H6bJaYk1\"\n",
        "sheet_name = \"Sheet_1\"\n",
        "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "result_df = pd.read_csv(url)\n",
        "\n",
        "sheet_id = \"1AA9MfqOtAAgO97__aomD79DciyT-PkRQ\"\n",
        "sheet_name = \"Sheet_1\"\n",
        "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "result_df = pd.read_csv(url)\n",
        "\n",
        "nasdaq100 = ['AAPL', 'MSFT', 'GOOGL', 'GOOG', 'AMZN',\n",
        "             'NVDA', 'TSLA', 'META', 'AVGO', 'ASML',\n",
        "             'PEP', 'COST', 'ADBE', 'AZN', 'CSCO',\n",
        "             'NFLX', 'AMD', 'CMCSA', 'TMUS', 'TXN',\n",
        "             'QCOM', 'HON', 'INTU', 'INTC', 'SNY',\n",
        "             'VZ', 'AMGN', 'SBUX', 'ISRG', 'AMAT',\n",
        "             'BKNG', 'ADI', 'MDLZ', 'PDD', 'GILD',\n",
        "             'ADP', 'VRTX', 'ABNB', 'LRCX', 'PYPL',\n",
        "             'REGN', 'EQIX', 'MU', 'CSX', 'SNPS',\n",
        "             'CME', 'CDNS', 'KLAC', 'NTES']"
      ],
      "metadata": {
        "id": "3g0KHl4YMTKd",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame()\n",
        "\n",
        "for stock in [\"EXPE\"]:\n",
        "  stock_df = yf.download(stock, start=\"2010-01-01\", end=\"2023-01-01\", progress=False)\n",
        "  stock_df = create_indicators(stock_df)\n",
        "  stock_df[\"signal\"] = 0\n",
        "\n",
        "  for index, row in stock_df.iterrows():\n",
        "    if index > 0 and index < stock_df.shape[0]-1 and stock_df[\"Close\"].iloc[index+1] > stock_df[\"Close\"].iloc[index]:\n",
        "      stock_df[\"signal\"].iloc[index] = 1\n",
        "\n",
        "  stock_df = stock_df.drop([\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Adj Close\"], axis=1)\n",
        "\n",
        "  data = pd.concat([data, stock_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "301D-_cbzUbS"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Preprocessing\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "input_columns = df.columns[:data.shape[1]-1]\n",
        "output_column = \"signal\"\n",
        "\n",
        "df[output_column] = df[output_column].astype(int)\n",
        "\n",
        "X = df[input_columns].values\n",
        "y = df[output_column].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight(\"balanced\", classes=[0, 1], y=y_train)\n",
        "class_weight = {cls: weight for cls, weight in zip([0, 1], class_weights)}\n",
        "class_weight"
      ],
      "metadata": {
        "id": "K-Gz1pgOMh8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f34027-d921-409b-c064-c8ee4694773f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.0276, 1: 0.9738438210765732}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=RandomForestRegressor(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_mean_squared_error',  # Negative MSE for optimization\n",
        "    cv=5  # Cross-validation folds\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters from the grid search\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train the Random Forest model using the best parameters\n",
        "model = RandomForestRegressor(**best_params, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Best Hyperparameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
        "\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWnDvwwnvfra",
        "outputId": "0045866f-3753-4a88-f513-7bb1e59e811b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Mean Squared Error: 0.256309453646911\n",
            "R-squared: -0.025954954989463763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LSTM Model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train_resampled.shape[1], 1)),\n",
        "\n",
        "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.LSTM(128),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=500, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('lstm_model.h5', save_best_only=True)\n",
        "\n",
        "model.fit(X_train_resampled, y_train_resampled, epochs=1000, batch_size=16, validation_split=0.3, class_weight=class_weight,\n",
        "          callbacks=[early_stopping, model_checkpoint])"
      ],
      "metadata": {
        "id": "IfSHE91eZonR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c5ETf4-OjGSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Conv1D model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "X_train_resampled = np.expand_dims(X_train_resampled, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "def create_advanced_model():\n",
        "    input_layer = keras.Input(shape=(X_train_resampled.shape[1], X_train_resampled.shape[2]))\n",
        "\n",
        "    x = layers.Conv1D(\n",
        "        filters=64, kernel_size=5, strides=2, padding=\"same\"\n",
        "    )(input_layer)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    # Add multiple residual blocks with varying depths and filter sizes\n",
        "    for _ in range(4):\n",
        "        x_res = x\n",
        "\n",
        "        x = layers.Conv1D(\n",
        "            filters=128, kernel_size=3, strides=1, padding=\"same\"\n",
        "        )(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "        x = layers.Conv1D(\n",
        "            filters=128, kernel_size=3, strides=1, padding=\"same\"\n",
        "        )(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        # Adjust the number of filters in x_res to match x\n",
        "        if x_res.shape[-1] != x.shape[-1]:\n",
        "            x_res = layers.Conv1D(filters=x.shape[-1], kernel_size=1, strides=1, padding=\"same\")(x_res)\n",
        "\n",
        "        x = layers.add([x, x_res])  # Residual connection\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D()(x)  # Global Average Pooling\n",
        "\n",
        "    x = layers.Dense(2048, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "\n",
        "    x = layers.Dense(1024, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "\n",
        "    x = layers.Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.L2())(x)\n",
        "\n",
        "    output_layer = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model = create_advanced_model()\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('/content/drive/MyDrive/best_model_2_gpt_deneme.h5', save_best_only=True)\n",
        "\n",
        "model.fit(X_train_resampled, y_train_resampled, epochs=1000, batch_size=128, validation_split=0.2,\n",
        "          callbacks=[early_stopping, model_checkpoint], class_weight=class_weight)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "J1wt4y6SAmBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0dbd504-5f59-4cca-92f0-46a1c9b0d596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "17/17 [==============================] - 20s 169ms/step - loss: 13.0333 - accuracy: 0.5052 - val_loss: 7.9172 - val_accuracy: 0.4527\n",
            "Epoch 2/1000\n",
            "17/17 [==============================] - 2s 123ms/step - loss: 5.4497 - accuracy: 0.5019 - val_loss: 3.2768 - val_accuracy: 0.5265\n",
            "Epoch 3/1000\n",
            "17/17 [==============================] - 2s 106ms/step - loss: 2.3699 - accuracy: 0.5109 - val_loss: 1.6253 - val_accuracy: 0.4489\n",
            "Epoch 4/1000\n",
            "17/17 [==============================] - 2s 96ms/step - loss: 1.3251 - accuracy: 0.5332 - val_loss: 1.0731 - val_accuracy: 0.5189\n",
            "Epoch 5/1000\n",
            "17/17 [==============================] - 1s 66ms/step - loss: 0.9590 - accuracy: 0.5469 - val_loss: 0.8650 - val_accuracy: 0.5530\n",
            "Epoch 6/1000\n",
            "17/17 [==============================] - 1s 58ms/step - loss: 0.8094 - accuracy: 0.5711 - val_loss: 0.8017 - val_accuracy: 0.4470\n",
            "Epoch 7/1000\n",
            "17/17 [==============================] - 1s 54ms/step - loss: 0.7471 - accuracy: 0.5763 - val_loss: 0.7555 - val_accuracy: 0.4621\n",
            "Epoch 8/1000\n",
            "17/17 [==============================] - 1s 58ms/step - loss: 0.7179 - accuracy: 0.5848 - val_loss: 0.7467 - val_accuracy: 0.4470\n",
            "Epoch 9/1000\n",
            "17/17 [==============================] - 1s 64ms/step - loss: 0.6959 - accuracy: 0.5924 - val_loss: 0.7395 - val_accuracy: 0.4640\n",
            "Epoch 10/1000\n",
            "17/17 [==============================] - 1s 56ms/step - loss: 0.6790 - accuracy: 0.6194 - val_loss: 0.7254 - val_accuracy: 0.4564\n",
            "Epoch 11/1000\n",
            "17/17 [==============================] - 1s 35ms/step - loss: 0.6783 - accuracy: 0.6128 - val_loss: 0.7299 - val_accuracy: 0.4830\n",
            "Epoch 12/1000\n",
            "17/17 [==============================] - 1s 31ms/step - loss: 0.6562 - accuracy: 0.6427 - val_loss: 0.7504 - val_accuracy: 0.4375\n",
            "Epoch 13/1000\n",
            "17/17 [==============================] - 1s 35ms/step - loss: 0.6434 - accuracy: 0.6573 - val_loss: 0.7459 - val_accuracy: 0.4735\n",
            "Epoch 14/1000\n",
            "17/17 [==============================] - 2s 130ms/step - loss: 0.6422 - accuracy: 0.6507 - val_loss: 0.7049 - val_accuracy: 0.5322\n",
            "Epoch 15/1000\n",
            "17/17 [==============================] - 1s 66ms/step - loss: 0.6569 - accuracy: 0.6261 - val_loss: 0.7089 - val_accuracy: 0.5455\n",
            "Epoch 16/1000\n",
            "17/17 [==============================] - 1s 48ms/step - loss: 0.6284 - accuracy: 0.6678 - val_loss: 0.6981 - val_accuracy: 0.5720\n",
            "Epoch 17/1000\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.6194 - accuracy: 0.6692 - val_loss: 0.7065 - val_accuracy: 0.5606\n",
            "Epoch 18/1000\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.6139 - accuracy: 0.6910 - val_loss: 0.7279 - val_accuracy: 0.5114\n",
            "Epoch 19/1000\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.5901 - accuracy: 0.7166 - val_loss: 0.7006 - val_accuracy: 0.5341\n",
            "Epoch 20/1000\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.5903 - accuracy: 0.7076 - val_loss: 0.7688 - val_accuracy: 0.5076\n",
            "Epoch 21/1000\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.5947 - accuracy: 0.7043 - val_loss: 0.8150 - val_accuracy: 0.4981\n",
            "Epoch 22/1000\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.5640 - accuracy: 0.7237 - val_loss: 0.7367 - val_accuracy: 0.4754\n",
            "Epoch 23/1000\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.5354 - accuracy: 0.7460 - val_loss: 0.8341 - val_accuracy: 0.5227\n",
            "Epoch 24/1000\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.5389 - accuracy: 0.7261 - val_loss: 0.8839 - val_accuracy: 0.4886\n",
            "Epoch 25/1000\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.5261 - accuracy: 0.7583 - val_loss: 0.8515 - val_accuracy: 0.5114\n",
            "Epoch 26/1000\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.4980 - accuracy: 0.7768 - val_loss: 0.8681 - val_accuracy: 0.5644\n",
            "Epoch 27/1000\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.4817 - accuracy: 0.7744 - val_loss: 0.8465 - val_accuracy: 0.5341\n",
            "Epoch 28/1000\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.4830 - accuracy: 0.7692 - val_loss: 0.7328 - val_accuracy: 0.5227\n",
            "Epoch 29/1000\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.5245 - accuracy: 0.7536 - val_loss: 1.0954 - val_accuracy: 0.5189\n",
            "Epoch 30/1000\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.4624 - accuracy: 0.7825 - val_loss: 0.8282 - val_accuracy: 0.5189\n",
            "Epoch 31/1000\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.4472 - accuracy: 0.7991 - val_loss: 0.8898 - val_accuracy: 0.5644\n",
            "Epoch 32/1000\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.3994 - accuracy: 0.8256 - val_loss: 1.1583 - val_accuracy: 0.5284\n",
            "Epoch 33/1000\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.4094 - accuracy: 0.8161 - val_loss: 1.0225 - val_accuracy: 0.5455\n",
            "Epoch 34/1000\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.4164 - accuracy: 0.8114 - val_loss: 1.0419 - val_accuracy: 0.5360\n",
            "Epoch 35/1000\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.3901 - accuracy: 0.8284 - val_loss: 0.9902 - val_accuracy: 0.5417\n",
            "Epoch 36/1000\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.3745 - accuracy: 0.8403 - val_loss: 1.1319 - val_accuracy: 0.5133\n",
            "Epoch 37/1000\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.3740 - accuracy: 0.8346 - val_loss: 0.9537 - val_accuracy: 0.5682\n",
            "Epoch 38/1000\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.3683 - accuracy: 0.8460 - val_loss: 1.6451 - val_accuracy: 0.5625\n",
            "Epoch 39/1000\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.3346 - accuracy: 0.8621 - val_loss: 1.2006 - val_accuracy: 0.5322\n",
            "Epoch 40/1000\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.3178 - accuracy: 0.8735 - val_loss: 1.3931 - val_accuracy: 0.5189\n",
            "Epoch 41/1000\n",
            "17/17 [==============================] - 0s 23ms/step - loss: 0.3541 - accuracy: 0.8573 - val_loss: 1.2466 - val_accuracy: 0.5322\n",
            "Epoch 42/1000\n",
            "17/17 [==============================] - 0s 25ms/step - loss: 0.3112 - accuracy: 0.8697 - val_loss: 1.6421 - val_accuracy: 0.5455\n",
            "Epoch 43/1000\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.3040 - accuracy: 0.8739 - val_loss: 1.6240 - val_accuracy: 0.5227\n",
            "Epoch 44/1000\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.3141 - accuracy: 0.8768 - val_loss: 1.1936 - val_accuracy: 0.5398\n",
            "Epoch 45/1000\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.2580 - accuracy: 0.9028 - val_loss: 1.7476 - val_accuracy: 0.5492\n",
            "Epoch 46/1000\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.3062 - accuracy: 0.8754 - val_loss: 1.3632 - val_accuracy: 0.5758\n",
            "Epoch 47/1000\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.2456 - accuracy: 0.8991 - val_loss: 2.0623 - val_accuracy: 0.5360\n",
            "Epoch 48/1000\n",
            "17/17 [==============================] - 1s 34ms/step - loss: 0.3400 - accuracy: 0.8592 - val_loss: 1.0116 - val_accuracy: 0.5398\n",
            "Epoch 49/1000\n",
            "17/17 [==============================] - 1s 31ms/step - loss: 0.2642 - accuracy: 0.9028 - val_loss: 1.4913 - val_accuracy: 0.5360\n",
            "Epoch 50/1000\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.2873 - accuracy: 0.8867 - val_loss: 1.3029 - val_accuracy: 0.5492\n",
            "Epoch 51/1000\n",
            "17/17 [==============================] - 1s 37ms/step - loss: 0.2319 - accuracy: 0.9090 - val_loss: 1.3724 - val_accuracy: 0.5549\n",
            "Epoch 52/1000\n",
            "17/17 [==============================] - 1s 46ms/step - loss: 0.2143 - accuracy: 0.9185 - val_loss: 1.8296 - val_accuracy: 0.5568\n",
            "Epoch 53/1000\n",
            "17/17 [==============================] - 1s 47ms/step - loss: 0.2479 - accuracy: 0.9043 - val_loss: 1.3037 - val_accuracy: 0.5720\n",
            "Epoch 54/1000\n",
            "17/17 [==============================] - 1s 31ms/step - loss: 0.2386 - accuracy: 0.9081 - val_loss: 1.7285 - val_accuracy: 0.5360\n",
            "Epoch 55/1000\n",
            "17/17 [==============================] - 1s 30ms/step - loss: 0.1984 - accuracy: 0.9213 - val_loss: 1.8266 - val_accuracy: 0.5833\n",
            "Epoch 56/1000\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 0.2109 - accuracy: 0.9232 - val_loss: 1.5646 - val_accuracy: 0.5701\n",
            "Epoch 57/1000\n",
            "17/17 [==============================] - 0s 29ms/step - loss: 0.1953 - accuracy: 0.9289 - val_loss: 1.8539 - val_accuracy: 0.5587\n",
            "Epoch 58/1000\n",
            " 7/17 [===========>..................] - ETA: 0s - loss: 0.1850 - accuracy: 0.9353"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(\"xu030-long-deneme.h5\")\n",
        "model = tf.keras.models.load_model(\"/content/lstm_model.h5\")\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "jqRgrzZg084k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5575f69b-3583-404e-9884-24e29dbbf726"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 1s 4ms/step - loss: 0.7151 - accuracy: 0.4883\n",
            "Test Loss: 0.7151261568069458\n",
            "Test Accuracy: 0.4883359372615814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for stock in [\"AAPL\"]:\n",
        "  predictions = []\n",
        "\n",
        "  stock_data = yf.download(stock, start=\"2023-01-01\", end=\"2023-08-10\", progress=False)\n",
        "  stock_data = create_indicators(stock_data)\n",
        "\n",
        "  stock_data[\"signal\"] = 0\n",
        "\n",
        "  for row in range(stock_data.shape[0]):\n",
        "    if row+1 != stock_data.shape[0] and stock_data[\"Close\"].iloc[row+1] > stock_data[\"Close\"].iloc[row]:\n",
        "      stock_data[\"signal\"].iloc[row] = 1\n",
        "\n",
        "  stock_data = stock_data.drop([\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"], axis=1)\n",
        "\n",
        "  for index, row in stock_data.iterrows():\n",
        "      x = row[1:data.shape[1]]\n",
        "\n",
        "      new_data = x.to_numpy().reshape(1, -1)\n",
        "      new_data = scaler.transform(new_data)\n",
        "      prediction = model.predict(new_data, verbose=None)\n",
        "\n",
        "      print(f\"Prediction for date {row[0]} {row[-1]}: {np.round(prediction[0][0])}\")\n",
        "\n",
        "      if np.round(prediction[0][0]) == row[\"signal\"]:\n",
        "        predictions.append(1)\n",
        "      elif np.round(prediction[0][0]) != row[\"signal\"]:\n",
        "        predictions.append(0)\n",
        "\n",
        "  print(f\"{stock} Accuracy: {predictions.count(1) / len(predictions) * 100}\")"
      ],
      "metadata": {
        "id": "GXskMvribBZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bee29bd-008a-4297-ed6e-a236b85cd0d2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for date 2023-03-30 00:00:00 1: [1.]\n",
            "Prediction for date 2023-03-31 00:00:00 0: [0.]\n",
            "Prediction for date 2023-04-03 00:00:00 0: [1.]\n",
            "Prediction for date 2023-04-04 00:00:00 0: [1.]\n",
            "Prediction for date 2023-04-05 00:00:00 1: [1.]\n",
            "Prediction for date 2023-04-06 00:00:00 0: [1.]\n",
            "Prediction for date 2023-04-10 00:00:00 1: [1.]\n",
            "Prediction for date 2023-04-11 00:00:00 0: [1.]\n",
            "Prediction for date 2023-04-12 00:00:00 1: [1.]\n",
            "Prediction for date 2023-04-13 00:00:00 1: [1.]\n",
            "Prediction for date 2023-04-14 00:00:00 1: [1.]\n",
            "Prediction for date 2023-04-17 00:00:00 1: [1.]\n",
            "Prediction for date 2023-04-18 00:00:00 0: [0.]\n",
            "Prediction for date 2023-04-19 00:00:00 0: [0.]\n",
            "Prediction for date 2023-04-20 00:00:00 0: [1.]\n",
            "Prediction for date 2023-04-21 00:00:00 1: [1.]\n",
            "Prediction for date 2023-04-24 00:00:00 0: [0.]\n",
            "Prediction for date 2023-04-25 00:00:00 0: [1.]\n",
            "Prediction for date 2023-04-26 00:00:00 1: [1.]\n",
            "Prediction for date 2023-04-27 00:00:00 1: [1.]\n",
            "Prediction for date 2023-04-28 00:00:00 1: [0.]\n",
            "Prediction for date 2023-05-01 00:00:00 0: [0.]\n",
            "Prediction for date 2023-05-02 00:00:00 0: [0.]\n",
            "Prediction for date 2023-05-03 00:00:00 0: [1.]\n",
            "Prediction for date 2023-05-04 00:00:00 1: [1.]\n",
            "Prediction for date 2023-05-05 00:00:00 0: [1.]\n",
            "Prediction for date 2023-05-08 00:00:00 1: [1.]\n",
            "Prediction for date 2023-05-09 00:00:00 0: [0.]\n",
            "Prediction for date 2023-05-10 00:00:00 1: [0.]\n",
            "Prediction for date 2023-05-11 00:00:00 0: [0.]\n",
            "Prediction for date 2023-05-12 00:00:00 1: [1.]\n",
            "Prediction for date 2023-05-15 00:00:00 1: [0.]\n",
            "Prediction for date 2023-05-16 00:00:00 1: [0.]\n",
            "Prediction for date 2023-05-17 00:00:00 1: [0.]\n",
            "Prediction for date 2023-05-18 00:00:00 0: [0.]\n",
            "Prediction for date 2023-05-19 00:00:00 1: [0.]\n",
            "Prediction for date 2023-05-22 00:00:00 0: [1.]\n",
            "Prediction for date 2023-05-23 00:00:00 0: [1.]\n",
            "Prediction for date 2023-05-24 00:00:00 1: [1.]\n",
            "Prediction for date 2023-05-25 00:00:00 1: [1.]\n",
            "Prediction for date 2023-05-26 00:00:00 1: [1.]\n",
            "Prediction for date 2023-05-30 00:00:00 0: [1.]\n",
            "Prediction for date 2023-05-31 00:00:00 1: [1.]\n",
            "Prediction for date 2023-06-01 00:00:00 1: [1.]\n",
            "Prediction for date 2023-06-02 00:00:00 1: [0.]\n",
            "Prediction for date 2023-06-05 00:00:00 1: [0.]\n",
            "Prediction for date 2023-06-06 00:00:00 0: [0.]\n",
            "Prediction for date 2023-06-07 00:00:00 0: [0.]\n",
            "Prediction for date 2023-06-08 00:00:00 1: [0.]\n",
            "Prediction for date 2023-06-09 00:00:00 1: [0.]\n",
            "Prediction for date 2023-06-12 00:00:00 1: [0.]\n",
            "Prediction for date 2023-06-13 00:00:00 0: [0.]\n",
            "Prediction for date 2023-06-14 00:00:00 0: [0.]\n",
            "Prediction for date 2023-06-15 00:00:00 0: [0.]\n",
            "Prediction for date 2023-06-16 00:00:00 1: [0.]\n",
            "Prediction for date 2023-06-20 00:00:00 0: [1.]\n",
            "Prediction for date 2023-06-21 00:00:00 1: [0.]\n",
            "Prediction for date 2023-06-22 00:00:00 0: [1.]\n",
            "Prediction for date 2023-06-23 00:00:00 0: [1.]\n",
            "Prediction for date 2023-06-26 00:00:00 1: [1.]\n",
            "Prediction for date 2023-06-27 00:00:00 1: [0.]\n",
            "Prediction for date 2023-06-28 00:00:00 0: [0.]\n",
            "Prediction for date 2023-06-29 00:00:00 1: [0.]\n",
            "Prediction for date 2023-06-30 00:00:00 1: [0.]\n",
            "Prediction for date 2023-07-03 00:00:00 0: [0.]\n",
            "Prediction for date 2023-07-05 00:00:00 0: [0.]\n",
            "Prediction for date 2023-07-06 00:00:00 1: [1.]\n",
            "Prediction for date 2023-07-07 00:00:00 1: [0.]\n",
            "Prediction for date 2023-07-10 00:00:00 1: [0.]\n",
            "Prediction for date 2023-07-11 00:00:00 0: [0.]\n",
            "Prediction for date 2023-07-12 00:00:00 1: [0.]\n",
            "Prediction for date 2023-07-13 00:00:00 0: [0.]\n",
            "Prediction for date 2023-07-14 00:00:00 1: [0.]\n",
            "Prediction for date 2023-07-17 00:00:00 0: [0.]\n",
            "Prediction for date 2023-07-18 00:00:00 0: [0.]\n",
            "Prediction for date 2023-07-19 00:00:00 0: [1.]\n",
            "Prediction for date 2023-07-20 00:00:00 1: [1.]\n",
            "Prediction for date 2023-07-21 00:00:00 0: [1.]\n",
            "Prediction for date 2023-07-24 00:00:00 1: [1.]\n",
            "Prediction for date 2023-07-25 00:00:00 1: [1.]\n",
            "Prediction for date 2023-07-26 00:00:00 0: [1.]\n",
            "Prediction for date 2023-07-27 00:00:00 1: [0.]\n",
            "Prediction for date 2023-07-28 00:00:00 1: [0.]\n",
            "Prediction for date 2023-07-31 00:00:00 0: [0.]\n",
            "Prediction for date 2023-08-01 00:00:00 0: [1.]\n",
            "Prediction for date 2023-08-02 00:00:00 0: [1.]\n",
            "Prediction for date 2023-08-03 00:00:00 1: [1.]\n",
            "Prediction for date 2023-08-04 00:00:00 1: [1.]\n",
            "Prediction for date 2023-08-07 00:00:00 1: [1.]\n",
            "Prediction for date 2023-08-08 00:00:00 0: [1.]\n",
            "Prediction for date 2023-08-09 00:00:00 0: [1.]\n",
            "EXPE Accuracy: 52.74725274725275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "buy_stocks = []\n",
        "\n",
        "for stock in result_df[\"STOCK\"].unique():\n",
        "  stock_data = yf.download(stock, start=\"2021-06-01\", end=\"2023-08-17\", progress=False)\n",
        "  stock_data = create_indicators(stock_data)\n",
        "\n",
        "  change = ((stock_data[\"Close\"].iloc[-1] - stock_data[\"Close\"].iloc[-2]) / stock_data[\"Close\"].iloc[-2])*100\n",
        "  change = round(change, 2)\n",
        "\n",
        "  stock_data = stock_data.drop([\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"], axis=1)\n",
        "\n",
        "  x = stock_data.iloc[-2]\n",
        "\n",
        "  new_data = x.to_numpy().reshape(1, -1)\n",
        "  new_data = scaler.transform(new_data)\n",
        "  prediction = model.predict(new_data, verbose=None)\n",
        "\n",
        "  if round(prediction[0][0]*100,2) > 75:\n",
        "    buy_stocks.append([stock, round(prediction[0][0]*100,2), change])\n",
        "\n",
        "buy_df = pd.DataFrame(buy_stocks, columns=[\"stock\", \"probability\", \"change\"]).sort_values(by=\"probability\", ascending=False)\n",
        "print(f'Pozitif kapanan hisse sayısı: {buy_df[buy_df[\"change\"] > 0].shape[0]}')\n",
        "print(f'Negatif kapanan hisse sayısı: {buy_df[buy_df[\"change\"] < 0].shape[0]}')\n",
        "print(f'Günlük değişim ortalaması: %{round(buy_df[\"change\"].sum()/buy_df.shape[0], 2)}\\n')\n",
        "buy_df"
      ],
      "metadata": {
        "id": "YASh8fggUiZk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "230139f7-e43c-494d-e2be-d481cda0427c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pozitif kapanan hisse sayısı: 2\n",
            "Negatif kapanan hisse sayısı: 3\n",
            "Günlük değişim ortalaması: %-0.94\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      stock  probability  change\n",
              "3  PGSUS.IS       100.00   -1.96\n",
              "1  GARAN.IS        99.71   -3.15\n",
              "4  THYAO.IS        96.80   -2.00\n",
              "0  ENKAI.IS        89.29    1.82\n",
              "2  KOZAL.IS        77.66    0.60"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6893b130-827f-4692-a16c-48046066fbd6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock</th>\n",
              "      <th>probability</th>\n",
              "      <th>change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PGSUS.IS</td>\n",
              "      <td>100.00</td>\n",
              "      <td>-1.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GARAN.IS</td>\n",
              "      <td>99.71</td>\n",
              "      <td>-3.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THYAO.IS</td>\n",
              "      <td>96.80</td>\n",
              "      <td>-2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENKAI.IS</td>\n",
              "      <td>89.29</td>\n",
              "      <td>1.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KOZAL.IS</td>\n",
              "      <td>77.66</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6893b130-827f-4692-a16c-48046066fbd6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6893b130-827f-4692-a16c-48046066fbd6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6893b130-827f-4692-a16c-48046066fbd6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e9a8ac35-5521-4880-8551-fe82e57eee5d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e9a8ac35-5521-4880-8551-fe82e57eee5d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e9a8ac35-5521-4880-8551-fe82e57eee5d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2023-08-08\n",
        "1\tBIMAS.IS\t98.39\t-1.34\n",
        "4\tPGSUS.IS\t97.33\t9.52\n",
        "2\tGARAN.IS\t96.60\t-0.43\n",
        "5\tPETKM.IS\t90.65\t5.20\n",
        "3\tGUBRF.IS\t90.02\t-0.40\n",
        "0\tARCLK.IS\t83.10\t1.14\n",
        "\n",
        "2023-08-08\n",
        "2\tPGSUS.IS\t100.00\t0.33\n",
        "1\tGARAN.IS\t97.05\t3.03\n",
        "0\tBIMAS.IS\t96.98\t1.54\n",
        "3\tSASA.IS\t95.37\t-3.57\n",
        "4\tTCELL.IS\t93.31\t0.94\n",
        "\n",
        "2023-08-09\n",
        "0\tBIMAS.IS\t99.82\t9.99\n",
        "2\tPETKM.IS\t99.82\t0.33\n",
        "3\tTHYAO.IS\t99.22\t-0.69\n",
        "1\tGARAN.IS\t92.52\t9.91\n",
        "\n",
        "2023-08-10\n",
        "2\tTOASO.IS\t98.16\t-4.08\n",
        "0\tGARAN.IS\t85.31\t2.83\n",
        "1\tSAHOL.IS\t76.00\t-0.84\n",
        "\n",
        "2023-08-11\n",
        "1\tKRDMD.IS\t100.00\t2.44\n",
        "2\tTHYAO.IS\t97.89\t2.79\n",
        "0\tFROTO.IS\t90.15\t2.24\n",
        "\n",
        "2023-08-14\n",
        "3\tTHYAO.IS\t99.93\t-1.62\n",
        "0\tAKBNK.IS\t99.74\t-2.20\n",
        "1\tGARAN.IS\t96.38\t0.63\n",
        "2\tTAVHL.IS\t87.66\t5.62\n",
        "\n",
        "2023-08-15\n",
        "3\tTHYAO.IS\t100.00\t-0.65\n",
        "0\tAKBNK.IS\t99.94\t0.53\n",
        "2\tSASA.IS\t99.93\t-0.99\n",
        "1\tGARAN.IS\t97.06\t-0.63\n",
        "\n",
        "2023-08-16\n",
        "1\tPGSUS.IS\t99.99\t-1.96\n",
        "0\tGARAN.IS\t99.91\t-3.15\n",
        "2\tSASA.IS\t99.26\t-1.28\n",
        "3\tPETKM.IS\t76.96\t0.98\n",
        "\n",
        "2023-08-17\n",
        "1\tPGSUS.IS\t100.00\t4.82\n",
        "5\tTOASO.IS\t100.00\t2.20\n",
        "0\tODAS.IS\t99.83\t-1.25\n",
        "6\tISCTR.IS\t97.81\t0.94\n",
        "7\tYKBNK.IS\t94.71\t2.77\n",
        "3\tSASA.IS\t84.09\t0.00\n",
        "4\tTAVHL.IS\t81.61\t0.39\n",
        "2\tSAHOL.IS\t79.27\t0.74\n",
        "\n",
        "2023-08-18\n",
        "0\tEKGYO.IS\t99.99\t-4.26\n",
        "3\tTOASO.IS\t99.95\t-3.51\n",
        "1\tGARAN.IS\t99.64\t-6.55\n",
        "2\tPGSUS.IS\t99.56\t-4.95\n",
        "4\tISCTR.IS\t96.21\t-3.49"
      ],
      "metadata": {
        "id": "3Ccc0G_6rn1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EZOJm4USTjy8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP7YJfgIcErMrbAaHRUpbdO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erendagasan/Eren-Dagasan-Personal/blob/main/llamadeneme.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(token='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')"
      ],
      "metadata": {
        "id": "NZkABuH2r2bU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDbBKi5-rA5w",
        "outputId": "45caec30-3db7-4ebe-f1ca-c26114964107"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "text_generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=device, truncation=True)\n",
        "\n",
        "prompt = \"Can we use past fundamental analysis ratios of stocks and label them with the past prices on that date to guess its current value by using same ratios but up to date with AI?\"\n",
        "sequences = text_generator(prompt, max_length=1000, num_return_sequences=1)\n",
        "\n",
        "for seq in sequences:\n",
        "    print(seq['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jjtf0cUjtymY",
        "outputId": "d5f86090-319f-42f3-d4ad-31cca16ed345"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Can we use past fundamental analysis ratios of stocks and label them with the past prices on that date to guess its current value by using same ratios but up to date with AI? \n",
            "Yes, we can, but with a few caveats.\n",
            "\n",
            "Here's why:\n",
            "\n",
            "**Ratios of stock prices are inherently subjective and can be influenced by various factors**. For instance, a stock's price might be influenced by sentiment, news, or market conditions. Moreover, past ratios may not accurately reflect the current market situation, as they are based on historical data.\n",
            "\n",
            "**Using past ratios to predict future stock prices is a complex task**. The relationship between past ratios and future stock prices is not straightforward, and it's challenging to establish a reliable model that can accurately predict future stock prices.\n",
            "\n",
            "**AI can help, but not entirely**. While AI can process vast amounts of data and identify patterns, it's essential to consider the limitations of AI models. For example, AI may not be able to capture the nuances of human emotions, social media sentiment, or other factors that can influence stock prices.\n",
            "\n",
            "**Here's a simplified example**:\n",
            "\n",
            "Suppose you want to use past ratios of stock prices to predict its current value. Let's say you have a historical dataset with the following ratios:\n",
            "\n",
            "| Date | Ratio | Stock Price |\n",
            "| --- | --- | --- |\n",
            "| 2020-01-01 | 1.2 | $100 |\n",
            "| 2020-02-01 | 1.1 | $105 |\n",
            "| 2020-03-01 | 1.05 | $110 |\n",
            "|... |... |... |\n",
            "\n",
            "To predict the stock price on a given date, you can use the same ratios but update them based on the current market situation. For example, if the stock price is $120 on a given date, you can use the updated ratio:\n",
            "\n",
            "| Date | Ratio | Stock Price |\n",
            "| --- | --- | --- |\n",
            "| 2020-01-01 | 1.2 | $100 |\n",
            "| 2020-02-01 | 1.1 | $105 |\n",
            "| 2020-03-01 | 1.05 | $110 |\n",
            "|... |... |... |\n",
            "\n",
            "However, this approach is still subject to the limitations mentioned earlier.\n",
            "\n",
            "**A more accurate approach**:\n",
            "\n",
            "To improve the accuracy of your predictions, consider the following:\n",
            "\n",
            "1. **Use multiple data sources**: Combine data from various sources, such as financial news websites, stock market indices, and analyst estimates, to get a more comprehensive view of the market situation.\n",
            "2. **Consider technical indicators**: Use technical indicators, such as moving averages, RSI, or Bollinger Bands, to identify potential trends or patterns in the stock price.\n",
            "3. **Use machine learning algorithms**: Train machine learning models to analyze the data and identify patterns that can help predict future stock prices.\n",
            "4. **Monitor sentiment and news**: Keep an eye on market sentiment and news to identify potential trends or changes in the market situation.\n",
            "\n",
            "By using a combination of these approaches, you can increase the accuracy of your predictions and make more informed decisions about your investments. However, keep in mind that past ratios of stock prices are inherently subjective and can be influenced by various factors, and AI is just one tool that can help, but not entirely.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import os\n",
        "\n",
        "def save_model_locally(model_name, save_path):\n",
        "    \"\"\"\n",
        "    Download and save a HuggingFace model and tokenizer locally\n",
        "\n",
        "    Args:\n",
        "        model_name (str): HuggingFace model identifier\n",
        "        save_path (str): Local directory path to save the model\n",
        "    \"\"\"\n",
        "    # Create the directory if it doesn't exist\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    # Load and save the tokenizer\n",
        "    print(f\"Loading tokenizer from {model_name}...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    tokenizer_path = os.path.join(save_path, \"tokenizer\")\n",
        "    print(f\"Saving tokenizer to {tokenizer_path}\")\n",
        "    tokenizer.save_pretrained(tokenizer_path)\n",
        "\n",
        "    # Load and save the model\n",
        "    print(f\"Loading model from {model_name}...\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    model_path = os.path.join(save_path, \"model\")\n",
        "    print(f\"Saving model to {model_path}\")\n",
        "    model.save_pretrained(model_path)\n",
        "\n",
        "    print(\"Model and tokenizer saved successfully!\")\n",
        "    return tokenizer_path, model_path\n",
        "\n",
        "# Example usage\n",
        "save_path = \"./llama_model\"  # You can change this to your preferred directory\n",
        "\n",
        "tokenizer_path, model_path = save_model_locally(model_name, save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM4C11fuwfm1",
        "outputId": "60699447-1923-493c-b387-80d535a77705"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tokenizer from meta-llama/Llama-3.2-1B-Instruct...\n",
            "Saving tokenizer to ./llama_model/tokenizer\n",
            "Loading model from meta-llama/Llama-3.2-1B-Instruct...\n",
            "Saving model to ./llama_model/model\n",
            "Model and tokenizer saved successfully!\n"
          ]
        }
      ]
    }
  ]
}